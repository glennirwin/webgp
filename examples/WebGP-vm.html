<!DOCTYPE html>
<html>
<head><title>WebGP-vm  A lightweight window manager for GPU viewports</title><meta charset="utf-8"></head>
<body style="margin: 0; background: linear-gradient(to bottom right, black, #333333); ">
    <canvas id="c" style="display: block; cursor: default; user-select: none;"></canvas>
    <script src="../src/webgp2.js"></script>
    <script src="toys/ClockMin.js"></script>
    <script src="toys/Font7.js"></script>
    <script src="toys/Font6.js"></script>
    <script src="toys/Font5.js"></script>
    <script src="toys/Font3.js"></script>
    <script src="toys/Primitives.js"></script>
<!--
  <script src="toys/vpInfo.js"></script>
    <script src="toys/MicAnalysis.js"></script>
    <script src="toys/Primitives.js"></script>
    <script src="toys/Prism.js"></script>
    <script src="toys/Galaxy.js"></script>
    <script src="toys/Tunnel.js"></script>
    <script src="toys/FirstAudio.js"></script>
    <script src="toys/Terrain.js"></script>
    <script src="toys/StarToy.js"></script>
    <script src="toys/PlasmaBall.js"></script>
    <script src="toys/ClockSpiral.js"></script>
    <script src="toys/ClockCircles.js"></script>
    <script src="toys/Cubescape.js"></script>
    <script src="toys/Cubes.js"></script>
    <script src="toys/Cube.js"></script>
    <script src="toys/Simplest.js"></script>
    <script src="toys/HG-SDF.js"></script>
    <script src="toys/Water.js"></script>
		<script src="toys/SDFx1.js"></script>
   -->
    <script>
				const VIEWPORT_MAX = 1000;		// Max number of viewports
				const MULTICLICK_MS = 330;	// ms delay to count clicks

        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();  // set up an audio context
        const canvas = document.getElementById("c");
				canvas.width = window.innerWidth - 1;
        canvas.height = window.innerHeight - 1;
        const GP = WebGP(canvas);

        // Comment this block to hide the log and controls
        //let log = GP.Util.initializeHeadsUpLog();
				let addNewItem = false;
        GP.Util.createShaderControls("GP");
				GP.Util.butdiv.append("           ");
				GP.Util.createButton("+", "addSomething();");
				GP.Util.createButton("Dump", "console.log(viewporter.getResultUnits().slice(0,stack.length)); console.log(stack);");
        let stats = document.createElement("paragraph");
        stats.appendChild(document.createTextNode(""));
        GP.Util.butdiv.appendChild(stats);

				const inputBlock = new GP.UniformBlock({		// This block is sent to the viewporter to relay to all blocks
            struct: {
								mouse: "vec4"
                ,date: "vec4"
								,resolution: "vec2"
								,now: "float"
                ,clicks: "int"
                ,wheel: "vec3"
            },
            initialize: {
								 mouse: [0.0,0.0,0.0,0.0]
                ,date: [0.0,0.0,0.0,0.0]  // Date in days
                ,resolution: [canvas.clientWidth, canvas.clientHeight]
								,now: window.performance.now()
                ,clicks: 0
                ,wheel: [0.0,0.0,0.0]
            }
        });

        // Feed mouse events into the inputBlock data
				let clickTime = 0.0, clicks = 0, mouse = [0.0, 0.0, 0.0, 0.0], wheel = [0.0, 0.0, 0.0], drag=false; dragFrom=[0,0];
				window.addEventListener('mousemove', e => { mouse[0]=e.clientX; mouse[1]=canvas.clientHeight-e.clientY; });   // if(e.buttons===0) drag=false;
				window.addEventListener('mouseup', e => { drag=false; mouse[2]=0.0; mouse[3]=0.0; });
        window.addEventListener('mousedown', e => { clicks=(Date.now()-clickTime<=MULTICLICK_MS)?clicks+1:1; clickTime=Date.now(); drag=true; dragFrom=[e.clientX,canvas.clientHeight-e.clientY]});
        window.addEventListener('wheel', e => { wheel=[e.deltaX, e.deltaY, e.deltaZ]; });

        // Resize updates the GL viewport and the resolution in the uniform block
				window.addEventListener('resize', event => {
					canvas.width = window.innerWidth - 1;
					canvas.height = window.innerHeight - 1;
					GP.gl.viewport(0, 0, canvas.clientWidth, canvas.clientHeight);
					inputBlock.set({ resolution: [canvas.clientWidth, canvas.clientHeight]});
				});

        const keybufferBlock = new GP.UniformBlock({		// for serialized keyboard actions (will come one at a time)
            struct: {
								Keyboard: "ivec3"    // x=down, y=up, z=pressed
            }
        });
        const keyboardBlock = new GP.UniformBlock({		// for direct keyboard sensing (names must correspond to values returned from keyevent.code)
            struct: {
								ArrowDown: "int", ArrowUp: "int",	ArrowLeft: "int", ArrowRight: "int", Escape: "int", Enter: "int", Minus: "int", Equal: "int", Delete: "int",
                Backslash: "int", Insert: "int", Home: "int", End: "int",  PageUp: "int", PageDown: "int", Space: "int", Backspace: "int", Tab: "int",
                F1: "int", F2: "int", F3: "int", F4: "int", F5: "int", F6: "int", F7: "int", F8: "int", F9: "int", F10: "int", F11: "int", F12: "int",
                ShiftLeft: "int",  ShiftRight: "int", ControlLeft: "int", ControlRight: "int", AltLeft: "int", AltRight: "int",
                Digit1: "int",  Digit2: "int",  Digit3: "int", Digit4: "int", Digit5: "int", Digit6: "int", Digit7: "int", Digit8: "int", Digit9: "int", Digit0: "int",
                KeyA: "int", KeyB: "int", KeyC: "int", KeyD: "int", KeyE: "int", KeyF: "int", KeyG: "int", KeyH: "int", KeyI: "int", KeyJ: "int",
                KeyK: "int", KeyL: "int", KeyM: "int", KeyN: "int", KeyO: "int", KeyP: "int", KeyQ: "int", KeyR: "int", KeyS: "int", KeyT: "int",
                KeyU: "int", KeyV: "int", KeyW: "int", KeyX: "int", KeyY: "int", KeyZ: "int"
            }
        });
        // Feed keyboard events to the keyboard block
        const keyBuffer = [];
        const keysToClear = [];  // to clear code after sending event
        function keyModifier(e) { return e.altKey && e.shiftKey ? 2048 : e.ctrlKey && e.shiftKey ? 4096 : e.ctrlKey && e.altKey ? 8192 :e.altKey ? 256 : e.shiftKey ? 512 : e.ctrlKey ? 1024 : 1; }
        function keyEvent(e,num) { keyboardBlock.setWrite( {[e.code]: num*keyModifier(e)} ); keysToClear.push(e.code); }
        function clearKeys() {
          while (keysToClear.length > 0) {
            keyboardBlock.setWrite( { [keysToClear[0]]: 0} );
            keysToClear.splice(0,1);
          }
        }
				window.addEventListener('keydown', e => {keyEvent(e,1); console.log("down:"+e.code); }  );
				window.addEventListener('keyup', e => keyEvent(e,-1) );
				window.addEventListener('keypress', e => { keyEvent(e,2); console.log("pressed:"+e.code); });
        //        function logKey(t,e) { console.log("key"+t+" "+(e.altKey?"~":"")+(e.ctrlKey?"^":"")+(e.shiftKey?"_":"")+e.key+"  "+e.keyCode+"  "+e.code); }

        window.addEventListener("gamepadconnected", function(e) {
          var gp = navigator.getGamepads()[e.gamepad.index];
          console.log("Gamepad connected at index %d: %s. %d buttons, %d axes.", gp.index, gp.id, gp.buttons.length, gp.axes.length);
        });
        window.addEventListener("gamepaddisconnected", function(e) {
            console.log("Gamepad disconnected from index %d: %s", e.gamepad.index, e.gamepad.id);
        });

			// common structure used by each viewport  (the viewporter maintains them all as vertex array)
			const viewStructure = {
					 viewport: "vec4",
              mouse: "vec4",
               date: "vec4",
				 resolution: "vec2",
					 		 time: "float",
					    delta: "float",
					      now: "float",
         sampleRate: "float",
					   clicks: "int",
              frame: "int",
              wheel: "vec3",
              state: "int",
				 projection: "mat4"
			};

			const viewInitial = {
				 viewport: [-2.0, -2.0, 0.0, 0.0],
					  mouse: [0.0, 0.0, 0.0, 0.0],
            date: [0.0, 0.0, 0.0, 0.0],
			 resolution: [0.0, 0.0],
						 time: -1.0,            //  time < 0 means dead
					  delta: 0.0,
							now: 0.0,
       sampleRate: 0.0,
					 clicks: 0,
 				    frame: 0,
            wheel: [0.0, 0.0, 0.0],
            state: 0,
			 projection: [-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0,-2.0]  // Should use a default identity matrix here I guess
		 };

		 function viewBlock() {							// Each viewbox array will share one of these
				return new GP.UniformBlock({ struct: viewStructure,  initialize: viewInitial });
		 }

     // Texture used by viewporter to share viewport locations and sizes
     const VIEWTEXTURE_SIZE = GP.Util.data2d(VIEWPORT_MAX);

		// Maintains viewBlock information, location and size for each component
		const viewporter = new GP.VertexComputer({
				units: 1000,
				struct: viewStructure,
				initializeObject: (i) => { return viewInitial;	},
        uniformBlocks: [inputBlock,keyboardBlock],
        textureOut: true,
        textureFeedback: "viewports",
				updateStep: {
            params: { viewports: "sampler2D" },
						glsl: GP.Util.cornerVectors + GP.Util.matrixFunctions + GP.Util.dataTextureMacros + `
#define VIEWPORT_MIN 0.07
#define AUTOMOVE_INCREMENT 0.01

void main() {
		if (i_time < 0.0) {  // Inactive or closed - copy everything
      o_viewport = i_viewport;
      o_mouse = i_mouse;
      o_date = i_date;
      o_resolution = u_resolution;
			o_time = i_time;
      o_delta = 0.0;
			o_now = u_now;
      o_sampleRate = i_sampleRate;
      o_clicks = i_clicks;
      o_frame = i_frame;
      o_wheel = i_wheel;
      o_state = i_state;
      o_projection = i_projection;

		} else {
			o_now = u_now;
      o_date = u_date;
			o_delta = u_now - i_now;
			o_time = i_time + o_delta/1000.0;  // Increment time for this unit
			o_resolution = u_resolution;
      o_frame = i_frame + 1;
      o_mouse = i_mouse;
			o_clicks = i_clicks;

      int newstate = i_state > 0 ? i_state : 0;  // default state to zero if not captured
      vec4 nv = i_viewport;              // new viewport

      if (u_ShiftLeft > 0 || u_ShiftRight > 0) {
        if (u_ArrowUp > 0)  nv.y = nv.y + 0.01;
        if (u_ArrowDown > 0)  nv.y = nv.y - 0.01;
        if (u_ArrowLeft > 0)  nv.x = nv.x - 0.01;
        if (u_ArrowRight > 0)  nv.x = nv.x + 0.01;
        if (u_wheel.x != 0.0) nv.x += u_wheel.x/u_resolution.x;
        if (u_wheel.y != 0.0) nv.y += u_wheel.y/u_resolution.y;
      }

      vec2 drag = 2.0 * u_mouse.zw/u_resolution;  // calculate mouse movement
      vec2 vpmouse = (inverse(i_projection) * vec4(u_mouse.xy / u_resolution * 2.0 - 1.0,0.0,1.0)).xy;  // convert mouse to viewport coord

			if (newstate < 1 && u_clicks > 0) {  // If dragging something or click
        float CLICK_THRESHOLD = 0.1 * 2.0/(i_viewport.z + i_viewport.w)/5.0;
				float distToMover = min(distance(moverTVector, abs(vpmouse)), distance(moverRVector,abs(vpmouse)));
				float distToSizer = distance(sizerVector,abs(vpmouse));
				float distToSizeVH = min(distance(sizeVVector,abs(vpmouse)),distance(sizeHVector,abs(vpmouse)));

				if (distToMover < CLICK_THRESHOLD && u_clicks == 3) {  					// CLOSE viewport on mover TRIPLE click
						o_time = -1.0;
						o_delta = 0.0;
						nv = vec4(-2.0,-2.0,0.0,0.0);
						o_mouse = vec4(0.0,0.0,0.0,0.0);
            o_frame = 0;
            o_state = 0;

				} else if (i_state == -1 || (i_state == 0 && distToMover < CLICK_THRESHOLD)) {                // moving
            nv.xy += drag;
            newstate = -1;

				} else if (i_state == -2 || (i_state == 0 && distToSizer < CLICK_THRESHOLD)) {                // Sizing
						if (sign(vpmouse.x) > 0.0 && sign(vpmouse.y) > 0.0) {          // top right
              nv.zw += drag;  // size it
						} else if (sign(vpmouse.x) > 0.0 && sign(vpmouse.y) < 0.0) {   // bottom right
							nv.zw = i_viewport.zw + vec2(drag.x, -drag.y);
							nv.xy = vec2(i_viewport.x, i_viewport.y + drag.y);
						} else if (sign(vpmouse.x) < 0.0 && sign(vpmouse.y) < 0.0) {   // Bottom left
							nv.zw =  i_viewport.zw - drag;
							nv.xy = i_viewport.xy + drag;
						} else {                                                   // Top left
							nv.zw =  i_viewport.zw + vec2(-drag.x, drag.y);
							nv.xy = vec2(i_viewport.x + drag.x,i_viewport.y);
						}
            newstate = -2;

				} else if (i_state == -3 || (i_state == 0 && distToSizeVH < CLICK_THRESHOLD)) {                    // size a side
					if (vpmouse.x > 0.0 && abs(vpmouse.y) < 0.4) {  					// right - horizontal - width
						nv.zw = i_viewport.zw + vec2( drag.x, 0.0);
					} else if (vpmouse.y > 0.0 && abs(vpmouse.x) < 0.4) {  		// top - vertical - height
						nv.zw =  i_viewport.zw + vec2(0.0, drag.y);
					} else if (vpmouse.y < 0.0 && abs(vpmouse.x) < 0.4) {  		// bottom - vertical - height
							nv.zw =  i_viewport.zw + vec2(0.0,-drag.y);
							nv.xy = vec2(i_viewport.x,i_viewport.y + drag.y);
					} else if (vpmouse.x < 0.0 && abs(vpmouse.y) < 0.4) {  			// left - horizontal - width
							nv.zw = i_viewport.zw + vec2(-drag.x,0.0);
							nv.xy = vec2(i_viewport.x + drag.x, i_viewport.y);
					}
          newstate = -3;
				}

	  }  // ends if clicked

    if (newstate == 0 && i_clicks == 0 && u_clicks > 0
      &&  lessThan(vec2(-0.99,-0.99),vpmouse) == lessThan(vpmouse,vec2(0.99,0.99))) {     // just clicked inside viewport
        newstate = 1;                                                                   // set mouse capture state
    }
    if (u_clicks == 0 && i_clicks > 0) {                              // just unclicked, capture off
      newstate = 0;
    }

    if (newstate > 0) {                                             // viewport mouse capture
      o_mouse.xy = vpmouse;
      o_mouse.zw = i_mouse.zw + drag;  // drag accumulates
      o_clicks = u_clicks;
    } else {
      o_clicks = 0;
    }

    if (u_clicks > 0 && newstate == 0 && i_state == 0) {                   // if not clicked on me, watch for others moving
        for (int i=0; i < ${VIEWPORT_MAX}; i++) {
            if (i != gl_VertexID) { // don't look at me
              vec4 ovp = TEXTURE_FETCH(u_viewports,i,${VIEWTEXTURE_SIZE});
              if (ovp.x == -2.0) break;  // reached end
              if (ovp.y < nv.y + nv.w && ovp.y + ovp.w > nv.y) {  // if aligned vertically
                if (nv.x > ovp.x && ovp.x + ovp.z > nv.x) nv.x += AUTOMOVE_INCREMENT;  // I move right if other is overlap from left
                if (nv.x < ovp.x && nv.x + nv.z > ovp.x) nv.x -= AUTOMOVE_INCREMENT;  // I move left if other is overlap from right
              }
              if (ovp.x < nv.x + nv.z && ovp.x + ovp.z > nv.x) {  // if aligned horizontally
                if (nv.y > ovp.y && ovp.y + ovp.w > nv.y) nv.y += AUTOMOVE_INCREMENT;  // I move up
                if (nv.y < ovp.y && nv.y + nv.w > ovp.y) nv.y -= AUTOMOVE_INCREMENT;  // I move down
              }
            }
        }
    }

    // Clamp location and size to GL space - boxes can't leave or be partially off screen
    if (nv.z > 2.0) nv.z = 2.0;
    if (nv.w > 2.0) nv.w = 2.0;
    if (nv.z < VIEWPORT_MIN || nv.w < VIEWPORT_MIN) { nv.zw = vec2(VIEWPORT_MIN,VIEWPORT_MIN); newstate = 0; }
    if (nv.x < -1.0) nv.x += AUTOMOVE_INCREMENT;
    if (nv.x+nv.z > 1.0) nv.x -= AUTOMOVE_INCREMENT;
    if (nv.y < -1.0) nv.y += AUTOMOVE_INCREMENT;
    if (nv.y+nv.w > 1.0) nv.y -= AUTOMOVE_INCREMENT;

    o_state = newstate;
    o_wheel = lessThan(vec2(-0.99,-0.99),u_mouse.xy) == bvec2(true,true) && lessThan(u_mouse.xy,vec2(0.99,0.99)) == bvec2(true,true) ? u_wheel : vec3(0.0, 0.0, 0.0);   // send wheel data only if mouse inside viewport
    o_projection = projection(nv);
    o_viewport = nv;

	}  // ends if time > 0.0  (if active)

  textureColor = o_viewport;
  gl_Position = TEXTURE_POS(gl_VertexID, ${VIEWTEXTURE_SIZE});
}`    },
								renderStep: {			// Renders nearest appropriate control point for a viewport
										glsl: GP.Util.cornerVectors+`
#define POINTSIZE_MAX 10.0
#define CLICKED_COLOR vec4(1.0,1.0,1.0,0.6)
#define HOVER_COLOR vec4(0.0,1.0,0.0,0.6)
#define TIME_MULT 10.0    // Animation time in ms
#define MOVE_FACTOR 150.0
vec4 jitter() {	return vec4(cos(i_time*TIME_MULT)/MOVE_FACTOR,sin(i_time*TIME_MULT)/MOVE_FACTOR*(i_resolution.x/i_resolution.y),0.,0.);	}

void main() {
    float CLICK_THRESHOLD = 0.1 * 2.0/(i_viewport.z + i_viewport.w)/5.0;
    vec2 vpmouse = (inverse(i_projection) * vec4(u_mouse.xy / u_resolution * 2.0 - 1.0,0.0,1.0)).xy;  // convert mouse to viewport coord
		float distToSizer = distance(sizerVector,abs(vpmouse.xy));
		float distToMover = min(distance(moverTVector, abs(vpmouse.xy)), distance(moverRVector,abs(vpmouse.xy)));
		float distToSizeVH = min(distance(sizeVVector,abs(vpmouse.xy)),distance(sizeHVector,abs(vpmouse.xy)));
		float md = CLICK_THRESHOLD * 25.0;
		float pulse = 0.0;
		float dist;
		if (distToMover < md && distToMover < distToSizer && distToMover < distToSizeVH) {
				dist = distToMover;
        gl_Position =  i_projection * vec4((abs(vpmouse.x) > abs(vpmouse.y) ? moverRVector : moverTVector) * sign(vpmouse.xy),0.0,1.0)
        	+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : jitter());
		} else if (distToSizer < md && distToSizer < distToMover && distToSizer < distToSizeVH) {
					dist = distToSizer;
					gl_Position =  i_projection * vec4(sizerVector * sign(vpmouse.xy),0.0,1.0)
							+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : vec4(jitter().x * sign(vpmouse.x), jitter().x * sign(vpmouse.y), 0.,0.));
		} else if (distToSizeVH < md && distToSizeVH < distToSizer && distToSizeVH < distToMover) {
				dist = distToSizeVH;
				gl_Position =  i_projection * vec4( (abs(vpmouse.x) > abs(vpmouse.y) ? sizeHVector : sizeVVector) * sign(vpmouse.xy),0.0,1.0)
						+ (dist < CLICK_THRESHOLD	? vec4(0.,0.,0.,0.)	: abs(vpmouse.x) > abs(vpmouse.y) ? vec4(jitter().x,0.,0.,0.) : vec4(0.,jitter().y,0.,0.));
		}
		gl_PointSize = dist < CLICK_THRESHOLD && u_clicks > 0 ? POINTSIZE_MAX * 1.5 :    // when clicked
										max(0.5, POINTSIZE_MAX - dist/md * POINTSIZE_MAX); // + pulse;
		vertexColor = dist < CLICK_THRESHOLD && u_clicks > 0 ? (u_clicks > 1 ? vec4(1.0,0.0,0.0,1.0) : CLICKED_COLOR) :    // when clicked, white
										 dist < CLICK_THRESHOLD ? HOVER_COLOR : vec4(1.0 - dist/md,0.0,0.0,0.6);
}`}
});

				let watch = GP.Util.stopWatch();
				const stack = [];   // Viewports to draw, each element is an array of GPU shaders that share a viewport uniformBlock
        let checkStack = false;
        const activeAudio = [];
        let date = new Date();

        function loop() {   // The render loop
            watch.mark();
						GP.Util.clear();

						clicks = (Date.now()-clickTime <= MULTICLICK_MS) ? clicks : drag ? 1 : 0;   // clear multi-clicks if time has passed
            if (drag) {  // send mouse difference each cycle when dragging
              mouse[2] = mouse[0] - dragFrom[0];  dragFrom[0] = mouse[0];
              mouse[3] = mouse[1] - dragFrom[1];  dragFrom[1] = mouse[1];  // console.log(mouse);  // can be handy
            }
            date.setTime(Date.now());  // update the date
						inputBlock.set({
								mouse: mouse,
                date: [date.getFullYear(),date.getMonth(),date.getDate(),date.getHours()*3600+date.getMinutes()*60+date.getSeconds()],
								now: window.performance.now(),     // time since start of browser, very accurate to micro seconds
                wheel: wheel,
								clicks: clicks
						}).write();  // Write all at once - other values may have changed via events
            wheel = [0.0,0.0,0.0];

            viewporter.step();  // Update/manipulate the viewports

            activeAudio.map(audioTexture => audioTexture.update());  // update active audio textures
						stack.map((item,index) => {
							viewporter.copyUnitToBlock(index,item[0].uniformBlocks[0]);	// shaders in item must share uniformBlocks, first in array is always the viewblock
							item.map(layer => { if (layer.ready) layer.step(); else layer.ready=checkUniforms(layer);  } );
						});

            clearKeys();
            if (clicks == 3 && checkStack == false) {
              checkStack = true;
            }
						if (watch.check() % 100 === 0) {
                stats.innerText = watch.stats();  watch.reset();
                if (checkStack) cleanStack();   // something may have been deleted
            }
            GP.Util.GPControls(loop);
        }

        // it all starts here, setup an itemlist, and go looping
        let itemlist = Object.keys(Kit);
				let nextcomp = 1;
				addSomething();    // to start with something
        //addItem([createTextureShader(viewporter.uniforms,[viewBlock()],"viewports")]);  // Uncomment to see the viewports texture
        loop();

				// Utility functions  ==================================
				function addSomething() {
					if (nextcomp > itemlist.length-1) nextcomp = 0;    // Update Max here
					addItem(loadItem(itemlist[nextcomp++]));
				}

				function addItem(item) {
          console.log(item);
          for (let layer of item) {
            layer.ready = !layer.uniforms || Object.keys(layer.uniforms).length == 0 ? true : checkUniforms(layer);  // Uniforms must be validated before step if there are textures to load
            if (layer.audio) layer.audio.map(at => getAudioData(at));   // Load audio and start when opening item
          }
					if (stack.length == VIEWPORT_MAX) { alert("out of viewport slots"); return; }
					viewporter.updateUnit(stack.length, {
						viewport: [Math.random()-0.5, Math.random()-0.5, 400/canvas.clientWidth, 300/canvas.clientHeight],  // random location and canvas size related size for now
						time: 0.0   // starts this item in the viewport engine
					});
					stack.push(item);
				}

				function loadItem(name) {    // set up to load array of layers for each viewport, only one now
          //let vpInfoTemplate = Kit["vpInfo"];

          let testtext = `The quick brown fox
jumped over the lazy dog

This is an example of simple text output and edit
using a simple algorithm for positioning (newlines)
Each character is an instance of a quad drawn
by a 100% procedural font inside a fragment shader
01234567890
!@#$%^&*()-_=+[]{}\\|;:'"/?.>,<~
ABCDEFGHIJKLMNOPQRSTUVWXYZ
abcdefghijklmnopqrstuvwxyz`;
					let template = Kit[name];
					if (!template || !template.model || !template.renderStep.fragment) {
							console.log("trying to load "+name+" and could not even get a fragment in the renderStep, so sad, all I got was "+template);
					} else {
            if (template.model === "text") {
              let blocks = [viewBlock()],  un = {}, params = {};
              if (template.resources) template.resources.map(i => blocks.push(getResource(i)));  // add resources to uniform block array
              if (template.textures) {
                un = loadTextures(template.textures);  // load the image
                for (i in un) params[i] = "sampler2D";  // add to frag params
              }
              if (template.sizing && template.sizing.positioning === "autochar") {  // GPU based character positioning (like terminal screens textpos is col(x),line(y))
                return  [createTextComputer("HelloGPU: "+name+" "+testtext, un, blocks, template, params)];
              } else {
                return [createTextQuadShader("Hello: "+name+" "+testtext, un, blocks, template, params)];
              }
            } else if (template.model === "quad") {
								let blocks = [viewBlock()],  un = {}, params = {};
                if (template.resources) template.resources.map(i => blocks.push(getResource(i)));  // add resources to uniform block array
                if (template.textures) {
                  un = loadTextures(template.textures);  // load the image
                  for (i in un) params[i] = "sampler2D";  // add to frag params
                }
                if (template.audio) {
                  let aa = [];  // audio attachments
                  for (i in template.audio) {
                    let audioTexture = GP.Util.buildAudioTexture(audioCtx,template.audio[i]);
                    un[i] = audioTexture.texture;
                    params[i] = "sampler2D"; // add to frag params
                    aa.push(audioTexture);
                  }
                  let qs = createQuadShader(un, blocks, template.renderStep.fragment,params);
                  qs.audio = aa;  // attach the audio textures to be loaded when item is opened
                  return [qs];  //,createQuadShader(un,blocks,vpInfoTemplate.renderStep.fragment)];
                } else {
                    return [createQuadShader(un, blocks, template.renderStep.fragment,params)]; //,createQuadShader(un,blocks,vpInfoTemplate.renderStep.fragment)];  // ane item could have multiple layers sharing the viewport
                }
						} else {
							console.log("Don't yet know how to load a model type of "+template.model+" for item "+name+", you may have to teach me");
						}
					}
				}

        function checkUniforms(computer) {    // assumes all uniforms are textures
          let result = true;
          for (t in computer.uniforms) {
            if (!(computer.uniforms[t] instanceof WebGLTexture)) {
              console.log(t+" not ready");
              return false;                // returns false if any are not WebGL textures
            }
          }
          return result;
        }

        function cleanStack() {
            let i=0, dead=0, units = viewporter.getResultUnits();  // array of viewport objects
            while (i<stack.length) {
              if (dead > 0) {
                units[i] = units[i+dead];   // advance by the number of dead encountered
                viewporter.updateUnit(i,units[i]);
              }
              if (units[i].time == -1.0) {   // dead unit
                let deaditem = stack[i];
                for (let layer of deaditem) {
                  if (layer.audio) layer.audio.map(at => dropAudio(at));  // Stop audio playing and copying
                  layer.destroy();
                }
                stack.splice(i,1);  // remove from stack
                dead++;  // will have to copy up from now til end
              } else i++;   // only advance if alive
            }
            checkStack = false;  // job is done
        }

        function getResource(r) {  // add other resources
          switch(r) {
            case "keyboard": return keyboardBlock;
          }
        }

        function loadTextures(un) {  // load a set of textures defined in a uniform structure with urls
          for (i in un) if (!(un[i] instanceof WebGLTexture)) loadTexture(un[i],i,un);
          return un;
        }

        function loadTexture(src, name, u) {    // load an image texture
          let xhr = new XMLHttpRequest();
          xhr.open("GET", src, true);
          xhr.responseType = "blob";
          xhr.onload = function(e) {
              let image = new Image();
              image.onload = function() {
                  console.log(name+ " loaded from "+src);
                  u[name] = GP.Util.buildImageTexture(this);
                  window.URL.revokeObjectURL(image.src);  // clean up
              };
              image.src = window.URL.createObjectURL(this.response);
          };
          xhr.send(null);
        }

        function dropAudio(texture) {    // called with an audio texture when a window with audio is closed
          if (texture.song) texture.song.stop();
          if (texture.microphone) { texture.microphone.disconnect(); texture.microphone = null; }
          let i = 0;
          while (i < activeAudio.length) {                  // Remove from list
            if (activeAudio[i] == texture) {
              activeAudio.splice(i,1);  // remove it
              console.log("activeAudio "+i+" removed");
              break;
            } else i++;
          }
        }

        function getAudioData(texture) {
          console.log("getting "+texture.url);
          if (texture.url === "microphone") {  // microphone needs permission
              navigator.mediaDevices.getUserMedia({audio: true}).then( function(stream) {
                texture.microphone = audioCtx.createMediaStreamSource(stream);
                texture.microphone.connect(texture.analyser);
                texture.analyser.connect(audioCtx.destination);
                activeAudio.push(texture);                          // Add this audioTexture to active list
                console.log("microphone connected");
              }, function(e) { console.log("microphone permission denied: "+e)});
          } else {
              request = new XMLHttpRequest();   // use XHR to load an audio track, and decodeAudioData to decode it to a buffer. Then we put the buffer into the source
              request.open('GET', texture.url, true);
              request.responseType = 'arraybuffer';
              request.onload = function() {
                audioCtx.decodeAudioData(request.response, function(buffer) {
                    texture.song = audioCtx.createBufferSource();
                    texture.song.buffer = buffer;
                    texture.song.connect(texture.analyser);
                    texture.analyser.connect(audioCtx.destination);
                    activeAudio.push(texture);                          // Add this audioTexture to active list
                    texture.song.addEventListener("ended", function() {
                      dropAudio(texture);
                    });
                    texture.song.start();
                });
              }
              request.send();
          }
        }

        function createTextComputer(text,u, blocks, template, fragparams) {		// A text shader that uses GPU to calculate char position and put out texture to be rendered via quad shader
          let line = 0, col = 0, npc = 0, tcols = 30, tlines = 10;
          let units = text.length + 100;
          let texWidth = GP.Util.data2d(units);
          let sizingCode = generateSizingCode(template);
          let instanceComputer = new GP.VertexComputer({   // each character will be handled separately
              units: units,
              struct: { color: "vec4", textpos: "vec2", char: "int",  style: "int", cursor: "int", index: "int"  },
              initializeObject: (i) => {
                if (i < text.length) {
                    let r = { color: [0.2,1.0,0.2,1.0], textpos: [col++, line], char: i+npc < text.length ? text.charCodeAt(i+npc) : -1, style: i, cursor: 1, index: i };
                    if (text.charCodeAt(i+npc) === 10 || text.charCodeAt(i+npc) === 13) { line++; col=0; }
                    return r;
                } else {
                    return { color: [0.2,1.0,0.2,1.0], textpos: [-1, -1], char: -1, style: 0, cursor: 0, index: i };
                }
              },
              uniforms: u,
		          uniformBlocks: blocks,
              textureOut: true,
              textureFeedback: "feedbackTexture",   // will be added to the uniforms and updated for the params
              updateStep: {  params: { feedbackTexture: "sampler2D" },  // could add automagically but useful to note for glsl usage
                glsl: GP.Util.dataTextureMacros + `
                void main() {
                  int newcursor = i_cursor;
                  vec2 newpos = i_textpos;
                  o_char = i_char;
                  o_style = i_style;
                  o_color = i_color;
                  o_index = i_index;
                  ${sizingCode}

                  vec4 cc = TEXTURE_FETCH(u_feedbackTexture,newcursor,${texWidth});   // cc = character at cursor position

                  bool inserted = false;
                  bool deleted = false;

                  #define INSERT_LETTER(k,l) o_char = k >= 512 ? l : l + 32;
                  #define INSERT_SYMBOL(l) o_char = l;
                  #define LETTER(k,l) if (k > 1) { if (gl_VertexID == i_cursor) INSERT_LETTER(k,l); if (i_cursor < gl_VertexID ) inserted=true; newcursor++; }
                  #define SYMBOL(k,l) if (k == 2) { if (gl_VertexID == i_cursor) INSERT_SYMBOL(l); if (i_cursor < gl_VertexID ) inserted=true; newcursor++; }
                  #define SHIFT_SYMBOL(k,l) if (k == 512) { if (gl_VertexID == i_cursor) INSERT_SYMBOL(l); if (i_cursor < gl_VertexID ) inserted=true; newcursor++; }

                  SYMBOL(u_Enter,10)  // Symbol keys

                  SYMBOL(u_Space,32)  // Symbol keys
                  SYMBOL(u_Digit0,48)
                  SYMBOL(u_Digit1,49)
                  SYMBOL(u_Digit2,50)
                  SYMBOL(u_Digit3,51)
                  SYMBOL(u_Digit4,51)
                  SYMBOL(u_Digit5,53)
                  SYMBOL(u_Digit6,54)
                  SYMBOL(u_Digit7,55)
                  SYMBOL(u_Digit8,56)
                  SYMBOL(u_Digit9,57)

                  SHIFT_SYMBOL(u_Digit1,33)  // !
                  SHIFT_SYMBOL(u_Digit2,64)  // @

                  LETTER(u_KeyA,65)    // Key pressed keys
                  LETTER(u_KeyB,66)
                  LETTER(u_KeyC,67)
                  LETTER(u_KeyD,68)
                  LETTER(u_KeyE,69)
                  LETTER(u_KeyF,70)
                  LETTER(u_KeyG,71)
                  LETTER(u_KeyH,72)
                  LETTER(u_KeyI,73)
                  LETTER(u_KeyJ,74)
                  LETTER(u_KeyK,75)
                  LETTER(u_KeyL,76)
                  LETTER(u_KeyM,77)
                  LETTER(u_KeyN,78)
                  LETTER(u_KeyO,79)
                  LETTER(u_KeyP,80)
                  LETTER(u_KeyQ,81)
                  LETTER(u_KeyR,82)
                  LETTER(u_KeyS,83)
                  LETTER(u_KeyT,84)
                  LETTER(u_KeyU,85)
                  LETTER(u_KeyV,86)
                  LETTER(u_KeyW,87)
                  LETTER(u_KeyX,88)
                  LETTER(u_KeyY,89)
                  LETTER(u_KeyZ,90)

                  if (u_ArrowRight > 0) newcursor++;
                  if (u_ArrowLeft > 0) newcursor--;

                  if (u_ArrowUp > 0) {   // scan backward for this x position on the prev line
                    vec4 c;
                    do {
                      newcursor--;
                      c = TEXTURE_FETCH(u_feedbackTexture,newcursor,${texWidth});
                    } while (c.w > -1.0 && (c.y == cc.y || (c.y == cc.y-1.0 && c.x > cc.x)) && newcursor > 0);
                  }

                  if (u_ArrowDown > 0) {   // scan forward for this x position on the next line
                    vec4 c;
                    do {
                      c = TEXTURE_FETCH(u_feedbackTexture,newcursor+1,${texWidth});
                    } while (c.w > -1.0 && (c.y == cc.y || (c.y == cc.y+1.0 && c.x <= cc.x)) && ++newcursor < ${units});
                  }

                if (u_Backspace == 1 && i_cursor > 0) { newcursor--; deleted=true; }  // backspace changes cursor so all must know
                if (u_Delete == 1 && i_cursor <= gl_VertexID && i_cursor < ${units-1}) deleted=true;

                if (inserted) {
                  vec4 cb = TEXTURE_FETCH(u_feedbackTexture,gl_VertexID-1,${texWidth});   // cb = character before
                  o_char = int(cb.w);  // I become the one before me so shift everything forward
                  o_style = int(cb.z);
                  newpos = cb.xy;
                  if (u_Enter == 2) {                        // inserting a return moves lines down
                    if (newpos.y == cc.y) newpos.x -= cc.x;
                    newpos.y += 1.0;
                  } else {                                  // stuff on same line moves forward
                    if (newpos.y == cc.y) newpos.x += 1.0;
                  }
                }

                if (deleted && gl_VertexID < ${units}-1 && newcursor <= gl_VertexID) {
                  vec4 ca = TEXTURE_FETCH(u_feedbackTexture,gl_VertexID+1,${texWidth});   // ca = character after
                  vec4 cur = newcursor==i_cursor ? cc : TEXTURE_FETCH(u_feedbackTexture,newcursor,${texWidth});   // cc = character at cursor position if moved (backspace)
                  o_char = int(ca.w);  // I become the one after me to shift everything back
                  o_style = int(ca.z);
                  newpos = ca.xy;
                  if (cur.w == 10.0 || cur.w == 13.0) {
                    newpos.y -= 1.0;
                    if (newpos.y == cur.y) newpos.x += cur.x;  // position at end of line
                  } else {
                    if (newpos.y == cur.y) newpos.x -= 1.0;    // stuff on same line moves back
                  }
                }

                if (u_clicks == 1) {   // find the closest character on the line - TODO: not very accurate
                  vec2 m = (u_mouse.xy + 1.0) / 2.0;
                  float line = ((1.0-m.y)/(ch*2.0)) / 2.0;
                  float col = m.x/(cw*2.0*wm) /2.0;
                  float dist = 2.0;
                  int cchar = -1;
                  for (int i=0;i<${units};i++) {
                    vec4 c = TEXTURE_FETCH(u_feedbackTexture,i,${texWidth});
                    float d = distance(c.xy,vec2(col,line));
                    if (d < dist) {
                      dist = d;
                      cchar = i;
                    }
                  }
                  if (cchar > -1) {
                    newcursor = cchar;
                  }
                }

                o_textpos = newpos;
                o_cursor = newcursor < 0 ? 0 : newcursor >= ${units} ? ${units-1} : newcursor;
                gl_Position = TEXTURE_POS(gl_VertexID,${texWidth});
                textureColor = vec4(newpos,float(o_style),float(o_char));
              }   ` },
                renderStep: {			                                            // Renders the cursor at the insert position
                    glsl: GP.Util.matrixFunctions + GP.Util.cornerVectors+`
              #define POINTSIZE_MAX 10.0
              #define CLICKED_COLOR vec4(1.0,1.0,1.0,0.6)
              #define HOVER_COLOR vec4(0.0,1.0,0.0,0.6)
              #define TIME_MULT 30.0    // Animations per second
              vec4 jitterV(float ch) {	return vec4(0.0,sin(u_time*TIME_MULT)*ch/3.0,0.,0.);	}  // only vertically for insert cursor
              void main() {
                  ${sizingCode}
                  if (i_cursor == gl_VertexID) {
                    gl_Position =  projection(vec4(u_viewport.x+cw*i_textpos.x*wm,u_viewport.y+u_viewport.w-((i_textpos.y+1.0)*ch), cw , ch)) * vec4(-1.0*wm,0.0,0.0,1.0) + jitterV(ch);
                    gl_PointSize = 4.0;
                    vertexColor = vec4(1.0,1.0,1.0,0.9);
                  }
              }`}
          });

        // addItem([createTextureShader(u,[viewBlock()],"feedbackTexture")],100.0);  // Uncomment to see the texture

          return new GP.VertexComputer({    // Draw/fill a set of quads specified by an array
		          units: 6,
              type: GP.gl.TRIANGLES,
              struct: { position: "vec2" },
              initializeBuffer: GP.Util.quadBuffer(),
              uniforms: u,
		          uniformBlocks: blocks,
              instanceComputer: instanceComputer,
		          renderStep: {  glsl: GP.Util.matrixFunctions + `
                out mat4 newproj;
                void main() {
                  v_textpos = i_textpos;
                  v_char = i_char;
                  v_style = i_style;
                  v_cursor = i_cursor;
                  v_color = i_color;
                  ${sizingCode}
                  newproj = projection(vec4(u_viewport.x+cw*i_textpos.x*wm,u_viewport.y+u_viewport.w-((i_textpos.y+1.0)*ch), cw ,ch));
                  gl_Position = newproj * vec4(i_position,0.0,1.0) ;
                }   `, fragment: template.renderStep.fragment,
                  fragmentParams: fragparams }
		      });
		    }

        function createTextQuadShader(text,u, blocks, template, fragparams) {		// A text shader that uses GPU to calculate char position and put out texture to be rendered via quad shader
          let line = 0, col = 0, npc = 0; tcols = 30, tlines = 10;
          let instanceArray = new GP.InstanceArray({
              units: text.length,
              divisor: 1,
              struct: { textpos: "vec2", char: "int",  style: "int"  },
              initializeObject: (i) => {
                if (text.charCodeAt(i+npc) === 10 || text.charCodeAt(i+npc) === 13) { line++; col=0; npc++;}
                return { textpos: [col++, line], char: i+npc < text.length ? text.charCodeAt(i+npc) : 0, style: i };
              }
          });
          return new GP.VertexComputer({    // Draw/fill a set of quads specified by an array
		          units: 6,
              type: GP.gl.TRIANGLES,
              struct: { position: "vec2" },
              initializeBuffer: GP.Util.quadBuffer(),
              uniforms: u,
		          uniformBlocks: blocks,
              instanceArray: instanceArray,
		          renderStep: {  glsl: GP.Util.matrixFunctions + `
                out mat4 newproj;

                void main() {
                  v_textpos = i_textpos;
                  v_char = i_char;
                  v_style = i_style;

                  ${generateSizingCode(template)}
                  newproj = projection(vec4(u_viewport.x+cw*i_textpos.x*wm,u_viewport.y+u_viewport.w-((i_textpos.y+1.0)*ch), cw ,ch));
                  gl_Position = newproj * vec4(i_position,0.0,1.0) ;
                }   `, fragment: template.renderStep.fragment,
                  fragmentParams: fragparams }
		      });
		    }

        function generateSizingCode(template) {
            if (template.sizing && template.sizing.fixedAspect) {
              if (template.sizing.scalable) {
                return `
                  float cw = ${template.sizing.width}.0 * u_viewport.z*2.0/u_resolution.x*${template.sizing.width}.0/2.0;    // for fixed width/height but scalable
                  float ch = ${template.sizing.height}.0 * u_viewport.z*2.0/u_resolution.x*${template.sizing.height}.0/2.0;
                  float wm = ${template.sizing.widthMultiplier ? template.sizing.widthMultiplier : "1.0"};\n`;
              } else {
                return `
                  float cw = ${template.sizing.width}.0/u_resolution.x*2.0;    // for fixed width/height
                  float ch = ${template.sizing.height}.0/u_resolution.y*2.0;
                  float wm = ${template.sizing.widthMultiplier ? template.sizing.widthMultiplier : "1.0"};\n`;
              }
            }
            if (template.sizing && !template.sizing.fixedAspect) {
                return `
                  float cw = ${template.sizing.width}.0 * u_viewport.z*2.0/u_resolution.x*3.0;   // for fonts that can alter aspect
                  float ch = ${template.sizing.height}.0 * u_viewport.w*2.0/u_resolution.y*3.0;
                  float wm = ${template.sizing.widthMultiplier ? template.sizing.widthMultiplier : "1.0"};\n`;
            }
            return  `
                  float cw = u_viewport.z/${tcols}.0;   // for scalable fonts
                  float ch = u_viewport.w/${tlines}.0;
                  float wm = 1.0;\n`;

        }



				function createQuadShader(u, blocks, fragglsl, fragparams) {		// A vanilla quad shader that uses the viewports projection
		      return new GP.VertexComputer({
		          units: 6,
		          type: GP.gl.TRIANGLES,
		          struct: { position: "vec2" },
              uniforms: u,
		          uniformBlocks: blocks,
		          initializeBuffer: GP.Util.quadBuffer(),
		          renderStep: {  glsl: `void main() {  gl_Position = u_projection * vec4(i_position,0.0,1.0); 	}   `, fragment: fragglsl, fragmentParams: fragparams }
		      });
		    }

        // utility function to return computer that renders a texture out of a uniform
        function createTextureShader(u, blocks, texname, divisor) {
            return createQuadShader(u, blocks, `
                    void main() {
                        vec2 uv = ((inverse(u_projection) * vec4((gl_FragCoord.xy/u_resolution.xy * 2.0 - 1.0),0.0,1.0)).xy + 1.0) / 2.0;
                        fragColor = texture(u_`+texname+`, uv)/${divisor || 1}.0;
                        fragColor.a += 0.5; // Boost the alpha so we see something
                    }`, { [texname]: "sampler2D"} );
        }
    </script>
</body>
</html>
