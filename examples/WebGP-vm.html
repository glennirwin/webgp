<!DOCTYPE html>
<html>
<head><title>WebGP-vm  A lightweight window manager for GPU viewports</title><meta charset="utf-8"></head>
<body style="margin: 0; background: linear-gradient(to bottom right, black, #333333); ">
    <canvas style="display: block; cursor: pointer; user-select: none;"></canvas>
    <script src="../src/webgp2.js"></script>
    <script src="toys/ClockMin.js"></script>
    <script src="toys/MicAnalysis.js"></script>
		<script src="toys/Primitives.js"></script>
		<script src="toys/Prism.js"></script>
    <script src="toys/Galaxy.js"></script>
    <script src="toys/Tunnel.js"></script>
    <script src="toys/FirstAudio.js"></script>
    <script src="toys/Terrain.js"></script>
		<script src="toys/StarToy.js"></script>
    <script src="toys/PlasmaBall.js"></script>
    <script src="toys/ClockSpiral.js"></script>
    <script src="toys/Cubescape.js"></script>
    <script src="toys/Cubes.js"></script>
<!--    <script src="toys/Cube.js"></script>
    <script src="toys/Simplest.js"></script>
    <script src="toys/ClockCircles.js"></script>
    <script src="toys/HG-SDF.js"></script>
    <script src="toys/Water.js"></script>
		<script src="toys/SDFx1.js"></script> -->
    <script>
				const VIEWPORT_MAX = 1000;		// Max number of viewports
				const MULTICLICK_MS = 330;	// ms delay to count clicks
                      // "Simplest",,"Cube","HGSDF","ClockCircles","SDFx1"
        let itemlist = ["ClockMin","MicAnalysis","Terrain","FirstAudio","PlasmaBall","Cubescape","ClockSpiral","Tunnel","StarToy","Galaxy","Prism","Cubes","Primitives"];  //

				const cornerVectors = `
// These are used to locate the control points
#define sizerVector vec2(1.0, 1.0)
#define moverTVector vec2(0.5, 1.0)
#define moverRVector vec2(1.0, 0.5)
#define sizeVVector vec2(0.0, 1.0)
#define sizeHVector vec2(1.0, 0.0)
				`;

				const matrixFunctions = `
mat4 frustum(float angle_of_view, float aspect_ratio, float z_near, float z_far) {
	 return mat4( vec4(1.0/tan(angle_of_view), 0.0, 0.0, 0.0),
								vec4(0.0, aspect_ratio/tan(angle_of_view),  0.0, 0.0),
								vec4(0.0, 0.0, (z_far+z_near)/(z_far-z_near), 1.0),
								vec4(0.0, 0.0, -2.0*z_far*z_near/(z_far-z_near), 0.0) ); }

mat4 scale(float x, float y, float z) {	return mat4(vec4(x,   0.0, 0.0, 0.0),
																										vec4(0.0, y,   0.0, 0.0),
																										vec4(0.0, 0.0, z,   0.0),
																										vec4(0.0, 0.0, 0.0, 1.0)); }

mat4 translate(float x, float y, float z) { return mat4(vec4(1.0, 0.0, 0.0, 0.0),
																												vec4(0.0, 1.0, 0.0, 0.0),
																												vec4(0.0, 0.0, 1.0, 0.0),
																												vec4(x,   y,   z,   1.0)); }

mat4 rotate_x(float theta) { return mat4(	vec4(1.0,         0.0,         0.0, 0.0),
																					vec4(0.0,  cos(theta),  sin(theta), 0.0),
																					vec4(0.0, -sin(theta),  cos(theta), 0.0),
																					vec4(0.0,         0.0,         0.0, 1.0)); }

mat4 rotate_y(float theta) { return mat4(	vec4(cos(theta), 0.0, sin(theta), 0.0),
																					vec4(0.0,  1.0,  0.0, 0.0),
																					vec4(-sin(theta), 0.0, cos(theta), 0.0),
																					vec4(0.0,         0.0,         0.0, 1.0)); }

mat4 rotate_z(float theta) {	return mat4( vec4(cos(theta), -sin(theta), 0.0, 0.0),
																						vec4(sin(theta), cos(theta), 0.0, 0.0),
																						vec4(0.0, 0.0, 1.0, 0.0),
																						vec4(0.0, 0.0, 0.0, 1.0)); }

mat4 projection(vec4 viewport) {
		return  	//frustum(radians(45.0), u_resolution.x/u_resolution.y, 0.5, 5.0) *  // no frustum needed (yet?)
							translate(viewport.x + viewport.z/2.0, viewport.y + viewport.w/2.0, 0.0) *
							scale(viewport.z/2.0, viewport.w/2.0, 1.0);   }
				`;

        const canvas = document.querySelector("canvas");
				canvas.width = window.innerWidth - 1;
        canvas.height = window.innerHeight - 1;
        const GP = WebGP(canvas);

        // Comment this block to hide the log and controls
        //let log = GP.Util.initializeHeadsUpLog();
				let addNewItem = false;
        GP.Util.createShaderControls("GP");
				GP.Util.butdiv.append("           ");
				GP.Util.createButton("+", "addSomething();");
				GP.Util.createButton("Dump", "console.log(viewporter.getResultUnits().slice(0,stack.length));");
        let stats = document.createElement("paragraph");
        stats.appendChild(document.createTextNode(""));
        GP.Util.butdiv.appendChild(stats);

        // set up an audio context
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

        // Texture used by viewporter to share viewport locations and sizes
        const VIEWTEXTURE_SIZE = GP.Util.data2d(VIEWPORT_MAX);
        const uniforms = {   // vm system textures, not passed to items
            viewports: GP.Util.buildDataTexture(VIEWTEXTURE_SIZE,VIEWTEXTURE_SIZE)
        };

        // Feed mouse events into the uniformBlock data
				let clickTime = 0.0, clicks = 0, mouse = [0.0, 0.0, -2.0, -2.0];
				window.addEventListener('mousemove', e => { mouse[0]=e.clientX; mouse[1]=canvas.clientHeight-e.clientY;  });
				window.addEventListener('mouseup', e => { mouse[2]=-2.0; mouse[3]=-2.0;  });
      	window.addEventListener('mousedown', e => { clicks=(Date.now()-clickTime<=MULTICLICK_MS)?clicks+1:1; clickTime=Date.now(); mouse[2]=e.clientX; mouse[3]=canvas.clientHeight-e.clientY; });

				const uniformBlock = new GP.UniformBlock({		// This block is sent to the viewporter to relay to all blocks
            struct: {
								mouse: "vec4",
								resolution: "vec2",
								now: "float",
								date: "float",
								clicks: "int"
            },
            initialize: {
								mouse: mouse,
                resolution: [canvas.clientWidth, canvas.clientHeight],
								now: Date.now(),
								date: Date.now()/86400000.0,
								clicks: 0
            }
        });

        // Resize updates the GL viewport and the resolution in the uniform block
				window.addEventListener('resize', event => {
					canvas.width = window.innerWidth - 1;
					canvas.height = window.innerHeight - 1;
					GP.gl.viewport(0, 0, canvas.clientWidth, canvas.clientHeight);
					uniformBlock.set({ resolution: [canvas.clientWidth, canvas.clientHeight]});
				});

        const keyboardBlock = new GP.UniformBlock({		// This block is sent to interested components (names must correspond to values returned from keyevent.code)
            struct: {
								ArrowDown: "int", ArrowUp: "int",	ArrowLeft: "int", ArrowRight: "int", Escape: "int", Enter: "int", Minus: "int", Equal: "int", Delete: "int",
                Backslash: "int", Insert: "int", Home: "int", End: "int",  PageUp: "int", PageDown: "int", Space: "int", Backspace: "int", Tab: "int",
                F1: "int", F2: "int", F3: "int", F4: "int", F5: "int", F6: "int", F7: "int", F8: "int", F9: "int", F10: "int", F11: "int", F12: "int",
                ShiftLeft: "int",  ShiftRight: "int", ControlLeft: "int", ControlRight: "int", AltLeft: "int", AltRight: "int",
                Digit1: "int",  Digit2: "int",  Digit3: "int", Digit4: "int", Digit5: "int", Digit6: "int", Digit7: "int", Digit8: "int", Digit9: "int", Digit0: "int",
                KeyA: "int", KeyB: "int", KeyC: "int", KeyD: "int", KeyE: "int", KeyF: "int", KeyG: "int", KeyH: "int", KeyI: "int", KeyJ: "int",
                KeyK: "int", KeyL: "int", KeyM: "int", KeyN: "int", KeyO: "int", KeyP: "int", KeyQ: "int", KeyR: "int", KeyS: "int", KeyT: "int",
                KeyU: "int", KeyV: "int", KeyW: "int", KeyX: "int", KeyY: "int", KeyZ: "int"
            }
        });

        // Feed keyboard events to the keyboard block
        function keyModifier(e) { return e.altKey && e.shiftKey ? 2048 : e.ctrlKey && e.shiftKey ? 4096 : e.ctrlKey && e.altKey ? 8192 :e.altKey ? 256 : e.shiftKey ? 512 : e.ctrlKey ? 1024 : 0; }
				window.addEventListener('keydown', e => keyboardBlock.setWrite( {[e.code]: 1+keyModifier(e)} ));
				window.addEventListener('keyup', e => keyboardBlock.setWrite( {[e.code]: -1-keyModifier(e)} ));
				window.addEventListener('keypress', e => keyboardBlock.setWrite( {[e.code]: 2+keyModifier(e)} ));
        //        function logKey(t,e) { console.log("key"+t+" "+(e.altKey?"~":"")+(e.ctrlKey?"^":"")+(e.shiftKey?"_":"")+e.key+"  "+e.keyCode+"  "+e.code); }

			// common structure used by each viewport  (the viewporter maintains them all as a set)
			const viewStructure = {
					 viewport: "vec4",
					 		mouse: "vec4",
				 resolution: "vec2",
					 		 time: "float",
					    delta: "float",
					      now: "float",
					     date: "float",
					   clicks: "int",
					 keyboard: "int",
					  vpmouse: "vec4",
				 projection: "mat4"
			};

			const viewInitial = {
				 viewport: [-2.0, -2.0, 0.0, 0.0],
					  mouse: [0.0, 0.0, 0.0, 0.0],
			 resolution: [0.0, 0.0],
						 time: -1.0,
					  delta: 0.0,
							now: 0.0,
						 date: 0.0,
					 clicks: 0,
 				 keyboard: 0,
					vpmouse: [0.0, 0.0, 0.0, 0.0],
			 projection: [-2.0,-2.0,-2.0,-2.0]
		 };

		 function viewBlock() {							// Each viewbox array will share one of these
				return new GP.UniformBlock({ struct: viewStructure,  initialize: viewInitial });
		 }

		// Maintains viewBlock information, location and size for each component
		const viewporter = new GP.VertexComputer({
				units: 1000,
				struct: viewStructure,
				initializeObject: (i) => { return viewInitial;	},
				uniforms: uniforms,
        uniformBlocks: [uniformBlock,keyboardBlock],
        textureOut: true,
				updateStep: {
            params: { viewports: "sampler2D" },
						glsl: cornerVectors + matrixFunctions + GP.Util.dataTextureMacros + `
void main() {
  vec4 nv = i_viewport;
		if (i_time < 0.0) {  // Inactive or closed
			o_time = i_time;
			o_now = u_now;
			o_date = i_date;
			o_delta = 0.0;
			o_mouse = i_mouse;
			o_resolution = u_resolution;
			o_projection = i_projection;
			o_vpmouse = i_vpmouse;
			o_clicks = i_clicks;
		} else {
			o_now = u_now;
			o_date = u_date;
			o_delta = u_now - i_now;
			o_time = i_time + o_delta/1000.0;  // Increment time for this unit
			o_resolution = u_resolution;
			o_projection = projection(i_viewport);
			o_clicks = u_clicks;

      if (u_ArrowUp > 0)  nv.y = nv.y + 0.01;
      if (u_ArrowDown > 0)  nv.y = nv.y - 0.01;
      if (u_ArrowLeft > 0)  nv.x = nv.x - 0.01;
      if (u_ArrowRight > 0)  nv.x = nv.x + 0.01;

			// Clamp location and size to GL space - boxes can't leave or be partially off screen
			if (nv.z > 2.0) nv.z = 2.0;
			if (nv.w > 2.0) nv.w = 2.0;
			if (nv.z < 0.0) nv.z = abs(nv.z);
			if (nv.w < 0.0) nv.w = abs(nv.w);
			if (nv.x < -1.0) nv.x = -1.0;
			if (nv.x+nv.z > 1.0) nv.x = 1.0 - nv.z;
			if (nv.y < -1.0) nv.y = -1.0;
			if (nv.y+nv.w > 1.0) nv.y = 1.0 - nv.w;

			vec2 newmouse = u_mouse.xy / u_resolution * 2.0 - 1.0;
			vec2 newclick = u_mouse.z == -2.0 ? u_mouse.zw : u_mouse.zw / u_resolution * 2.0 - 1.0;
			o_mouse.xy = newmouse;
			vec4 mouse = inverse(i_projection) * vec4(newmouse,0.0,1.0);
			vec4 click = u_mouse.z == -2.0 ? vec4(u_mouse.zw,0.0,0.0) : inverse(i_projection) * vec4(newclick,0.0,1.0);
			o_vpmouse.xy = mouse.xy;   // set to the view projected value for convenience down the line
			o_vpmouse.zw = click.xy == i_vpmouse.zw ? click.xy : vec2(-2.0, -2.0); // send the click only if it was within the viewport (on the click)

      if (u_mouse.z > -2.0 && i_vpmouse.z == -2.0) {  // not clicked on me so watch for others moving
          for (int i=0;i<1000;i++) {
              if (i != gl_VertexID) {
                vec4 ovp = TEXTURE_FETCH(u_viewports,i,${VIEWTEXTURE_SIZE});
                if (ovp.x == -2.0) break;  // reached end
                if (ovp.y < nv.y + nv.w && ovp.y + ovp.w > nv.y) {  // if aligned vertically
                  if (nv.x > ovp.x && ovp.x + ovp.z > nv.x) {
                    nv.x += 0.01;  // I move right if other is overlap from left
                  }
                  if (nv.x < ovp.x && nv.x + nv.z > ovp.x) {
                    nv.x -= 0.01;  // I move left if other is overlap from right
                  }
                }
                if (ovp.x < nv.x + nv.z && ovp.x + ovp.z > nv.x) {  // if aligned horizontally
                  if (nv.y > ovp.y && ovp.y + ovp.w > nv.y) {
                    nv.y += 0.01;  // I move up
                  }
                  if (nv.y < ovp.y && nv.y + nv.w > ovp.y) {
                    nv.y -= 0.01;  // I move down
                  }
                }
              }
          }
      }

			if (o_vpmouse.z == -2.0 && click.x > -2.0 && click.y > -2.0) {  // If clicked

				float CLICK_THRESHOLD = 30.0/((i_viewport.z * u_resolution.x + i_viewport.w * u_resolution.y)/2.0) + 0.01;

				float distToMover = i_viewport.xy == i_mouse.zw ? 0.0 : min(distance(moverTVector, abs(mouse.xy)), distance(moverRVector,abs(mouse.xy)));
				float distToSizer = i_viewport.zw == i_mouse.zw ? 0.0 : distance(sizerVector,abs(mouse.xy));
				float distToSizeVH = i_viewport.xw == i_mouse.zw ? 0.0 : min(distance(sizeVVector,abs(mouse.xy)),distance(sizeHVector,abs(mouse.xy)));

				if (distToMover < CLICK_THRESHOLD && u_clicks == 3) {  					// CLOSE viewport on mover tripleclick
						o_time = -1.0;
						o_delta = 0.0;
						o_viewport = vec4(-2.0,-2.0,-0.0,0.0);
						o_projection = projection(nv);
						o_mouse = vec4(0.0,0.0,0.0,0.0);
						o_vpmouse = vec4(0.0,0.0,0.0,0.0);
						return;

				} else if (distToMover == -1.0 || distToMover < CLICK_THRESHOLD) {  // moving is simple enough
						nv.xy = i_viewport.xy + newmouse - i_mouse.xy;  // move it
							o_mouse.zw = nv.xy; // keep the click with the location to lock it in

				} else if (distToSizer == -1.0 || distToSizer < CLICK_THRESHOLD) {  // Sizing is more complex as both size and loc must be moved sometimes
						if (sign(mouse.x) > 0.0 && sign(mouse.y) > 0.0) {  // top right
								nv.zw = newmouse - i_viewport.xy;  // size it
							o_mouse.zw = nv.zw; // keep the click with the location to lock it in
						} else if (sign(mouse.x) > 0.0 && sign(mouse.y) < 0.0) {  // bottom right
							nv.zw = i_viewport.zw + vec2(newmouse.x - i_mouse.x, i_mouse.y - newmouse.y);  // size it
							nv.xy = vec2(i_viewport.x, i_viewport.y + newmouse.y - i_mouse.y);  // Must alter y location only
							o_mouse.zw = nv.zw; // keep the click with the location to lock it in
						} else if (sign(mouse.x) < 0.0 && sign(mouse.y) < 0.0) {   // Bottom left - alters location and size
							nv.zw =  i_viewport.zw + i_mouse.xy - newmouse;
							nv.xy = i_viewport.xy + newmouse - i_mouse.xy;
							o_mouse.zw = nv.zw; // keep the click with the location to lock it in
						} else {  // Top left
							nv.zw =  i_viewport.zw + vec2(i_mouse.x - newmouse.x, newmouse.y - i_mouse.y);
							nv.xy = vec2(i_viewport.x + newmouse.x - i_mouse.x,i_viewport.y);  // Must alter y location only
							o_mouse.zw = nv.zw; // keep the click with the location to lock it in
						}

				} else if (distToSizeVH == -1.0 || distToSizeVH < CLICK_THRESHOLD) {   // drag a side
					if (mouse.x > 0.0 && abs(mouse.y) < 0.4) {  												// right - horizontal - width
						nv.zw = i_viewport.zw + vec2( newmouse.x - i_mouse.x,0.0);  							// size its width
						o_mouse.zw = nv.xw; 			// keep the click with the location to lock it in

					} else if (mouse.y > 0.0 && abs(mouse.x) < 0.4) {  									// top - vertical - height
						nv.zw =  i_viewport.zw + vec2(0.0, newmouse.y - i_mouse.y);  								// size its height
						o_mouse.zw = nv.xw; // keep the click with the location to lock it in

					} else if (mouse.y < 0.0 && abs(mouse.x) < 0.4) {  									// bottom - vertical - height
							nv.zw =  i_viewport.zw + vec2(0.0,i_mouse.y - newmouse.y);  								// size its height
							nv.xy = vec2(i_viewport.x,i_viewport.y + newmouse.y - i_mouse.y);  // Must alter y location too
							o_mouse.zw = nv.xw; // keep the click with the location to lock it in

					} else if (mouse.x < 0.0 && abs(mouse.y) < 0.4) {  												// left - horizontal - width
							nv.zw = i_viewport.zw + vec2(i_mouse.x - newmouse.x,0.0);  							// size its width
							nv.xy = vec2(i_viewport.x + newmouse.x - i_mouse.x, i_viewport.y);  // Must alter x location too
							o_mouse.zw = nv.xw; 			// keep the click with the location to lock it in
					}

				} else {				// send the click only if it was within the viewport (on the click)
          o_vpmouse.zw = lessThan(vec2(-0.99,-0.99),click.xy) == bvec2(true,true) && lessThan(click.xy,vec2(0.99,0.99)) == bvec2(true,true) ? click.xy : vec2(-2.0, -2.0);
				}
	  }    // ends if clicked

	}  // if time > 0.0  (active)

  o_projection = projection(nv);
  textureColor = nv;
  o_viewport = nv;
  gl_Position = TEXTURE_POS(gl_VertexID, ${VIEWTEXTURE_SIZE});

}
												`},
								renderStep: {			// Renders nearest appropriate control point for a viewport
										glsl: cornerVectors+`
#define POINTSIZE_MAX 10.0
#define CLICKED_COLOR vec4(1.0,1.0,1.0,0.6)
#define HOVER_COLOR vec4(0.0,1.0,0.0,0.6)
#define TIME_MULT 10.0    // Animation time in ms
#define PULSE_SIZE 3.0
#define MOVE_FACTOR 150.0
vec4 jitter() {	return vec4(cos(i_time*TIME_MULT)/MOVE_FACTOR,sin(i_time*TIME_MULT)/MOVE_FACTOR*(i_resolution.x/i_resolution.y),0.,0.);	}

void main() {
		float CLICK_THRESHOLD = 30.0/((i_viewport.z * u_resolution.x + i_viewport.w * u_resolution.y)/2.0) + 0.01;
		float distToSizer = distance(sizerVector,abs(i_vpmouse.xy));
		float distToMover = min(distance(moverTVector, abs(i_vpmouse.xy)), distance(moverRVector,abs(i_vpmouse.xy)));
		float distToSizeVH = min(distance(sizeVVector,abs(i_vpmouse.xy)),distance(sizeHVector,abs(i_vpmouse.xy)));
		float md = CLICK_THRESHOLD * 25.0;
		float pulse = 0.0;
		float dist;
		if (distToMover < md && distToMover < distToSizer && distToMover < distToSizeVH) {
				dist = distToMover;
        gl_Position =  i_projection * vec4((abs(i_vpmouse.x) > abs(i_vpmouse.y) ? moverRVector : moverTVector) * sign(i_vpmouse.xy),0.0,1.0)
        	+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : jitter());
		} else if (distToSizer < md && distToSizer < distToMover && distToSizer < distToSizeVH) {
					dist = distToSizer;
					gl_Position =  i_projection * vec4(sizerVector * sign(i_vpmouse.xy),0.0,1.0)
							+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : vec4(jitter().x * sign(i_vpmouse.x), jitter().x * sign(i_vpmouse.y), 0.,0.));
		} else if (distToSizeVH < md && distToSizeVH < distToSizer && distToSizeVH < distToMover) {
				dist = distToSizeVH;
				gl_Position =  i_projection * vec4( (abs(i_vpmouse.x) > abs(i_vpmouse.y) ? sizeHVector : sizeVVector) * sign(i_vpmouse.xy),0.0,1.0)
						+ (dist < CLICK_THRESHOLD	? vec4(0.,0.,0.,0.)	: abs(i_vpmouse.x) > abs(i_vpmouse.y) ? vec4(jitter().x,0.,0.,0.) : vec4(0.,jitter().y,0.,0.));
		}
		//pulse = (dist < CLICK_THRESHOLD ? sin(i_time*TIME_MULT*10.0) * PULSE_SIZE : 0.0 );
		gl_PointSize = i_mouse.zw == i_viewport.zw || i_mouse.zw == i_viewport.xy ? POINTSIZE_MAX * 1.5 :    // when clicked
										max(0.5, POINTSIZE_MAX - dist/md * POINTSIZE_MAX); // + pulse;
		vertexColor = i_mouse.zw == i_viewport.zw || i_mouse.zw == i_viewport.xy || i_mouse.zw == i_viewport.xw ? CLICKED_COLOR :    // when clicked, white
										 dist < CLICK_THRESHOLD ? HOVER_COLOR : vec4(1.0 - dist/md,0.0,0.0,0.6);
}`}
});
				let watch = GP.Util.stopWatch();
				const stack = [];   // Viewports to draw, each element is an array of GPU shaders that share a viewport uniformBlock
        let checkStack = false;
        const activeAudio = [];

        function loop() {
            watch.mark();
						GP.Util.clear();

            activeAudio.map(audioTexture => audioTexture.update());  // update active audio textures

						clicks = (Date.now()-clickTime <= MULTICLICK_MS) ? clicks : 0;   // clear clicks if time has passed
						uniformBlock.set({
								mouse: mouse,
								now: window.performance.now(),  //newTime - startTime,    // time since start
								date: Date.now() / 86400000.0,
								clicks: clicks
						}).write();  // Write all at once - other values may have changed via events

						viewporter.step();  // Update the viewports
            uniforms.viewports = viewporter.getResultTexture();
						stack.map((item,index) => {
							viewporter.copyUnitToBlock(index,item[0].uniformBlocks[0]);	// All shaders in item must share uniformBlocks, first in array is always viewblock
							item.map(layer => { if (layer.ready) layer.step(); else layer.ready=checkUniforms(layer);  } );
						});

            if (clicks == 3 && checkStack == false) {
              checkStack = true;
            }
						if (watch.check() % 100 === 0) {
                stats.innerText = watch.stats();  watch.reset();
                if (checkStack) cleanStack();   // something may have been deleted
            }
            GP.Util.GPControls(loop);
        }

				let nextcomp = 0;
				addSomething();    // to start with something
        //addItem([createTextureShader(uniforms,[viewBlock()],"viewports")]);  // Uncomment to see the viewports texture
        loop();

				// Utility functions  ==================================
				function addSomething() {
					if (nextcomp > itemlist.length-1) nextcomp = 0;    // Update Max here
					addItem(itemlist[nextcomp++]);
				}

				function addItem(itemname) {
          item = loadKit(itemname);
          for (let layer of item) {
            layer.ready = !layer.uniforms || Object.keys(layer.uniforms).length == 0 ? true : checkUniforms(layer);  // Uniforms must be validated before step if there are textures to load
            if (layer.audio) {   // Load audio and start when opening item
              layer.audio.map(at => getAudioData(at));
            }
          }
					if (stack.length == VIEWPORT_MAX) { alert("out of viewport slots"); return; }
					viewporter.updateUnit(stack.length, {
						viewport: [Math.random()*1.9-0.9, Math.random()*1.9-0.9, 400/canvas.clientWidth, 300/canvas.clientHeight],
						time: 0.0   // starts this item in the viewport engine
					});
					stack.push(item);
				}

				function loadKit(name) {
					let template = Kit[name];
					if (!template || !template.model || !template.renderStep.fragment) {
							console.log("trying to load "+name+" and could not even get a fragment in the renderStep, so sad, all I got was "+template);
					} else {
						if (template.model = "quad") {
								let blocks = [viewBlock()],  un = {}, params = {};
                if (template.resources) template.resources.map(i => blocks.push(getResource(i)));  // add resources to uniform block array
                if (template.textures) {
                  un = loadTextures(template.textures);  // load the image
                  for (i in un) params[i] = "sampler2D";  // add to frag params
                }
                if (template.audio) {
                  let aa = [];  // audio attachments
                  for (i in template.audio) {
                    let audioTexture = GP.Util.buildAudioTexture(audioCtx,template.audio[i]);
                    un[i] = audioTexture.texture;
                    params[i] = "sampler2D"; // add to frag params
                    aa.push(audioTexture);
                  }
                  let qs = createQuadShader(un, blocks, template.renderStep.fragment,params);
                  qs.audio = aa;  // attach the audio textures to be loaded when item is opened
                  return [qs];
                } else {
                    return [createQuadShader(un, blocks, template.renderStep.fragment,params)];  // ane item could have multiple layers sharing the viewport
                }
						} else {
							console.log("Don't yet know how to load a model type of "+template.model+" for item "+name+", you may have to teach me");
						}
					}
				}

        function checkUniforms(computer) {    // assumes all uniforms are textures
          let result = true;
          for (t in computer.uniforms) {
            if (!(computer.uniforms[t] instanceof WebGLTexture)) {
              console.log(t+" not ready");
              return false;                // returns false if any are not WebGL textures
            }
          }
          return result;
        }

        function cleanStack() {
            let i=0, dead=0, units = viewporter.getResultUnits();  // array of viewport objects
            while (i<stack.length) {
              if (dead > 0) {
                units[i] = units[i+dead];   // advance by the number of dead encountered
                viewporter.updateUnit(i,units[i]);
              }
              if (units[i].time == -1.0) {   // dead unit
                let deaditem = stack[i];
                for (let layer of deaditem) {
                  if (layer.audio) layer.audio.map(at => dropAudio(at));  // Stop audio playing and copying
                  layer.destroy();
                }
                stack.splice(i,1);  // remove from stack
                dead++;  // will have to copy up from now til end
              } else i++;   // only advance if alive
            }
            checkStack = false;  // job is done
        }

        function getResource(r) {  // add other resources, microphone?, webcam?
          switch(r) {
            case "keyboard": return keyboardBlock;
          }
        }

        function loadTextures(un) {
          for (i in un) {
            if (!(un[i] instanceof WebGLTexture)) loadTexture(un[i],i,un);
          }
          return un;
        }

        function loadTexture(src, name, u) {
          let xhr = new XMLHttpRequest();
          xhr.open("GET", src, true);
          xhr.responseType = "blob";
          xhr.onload = function(e) {
              let image = new Image();
              image.onload = function() {
                  console.log(name+ " loaded from "+src);
                  u[name] = GP.Util.buildImageTexture(this);
                  window.URL.revokeObjectURL(image.src);  // clean up
              };
              image.src = window.URL.createObjectURL(this.response);
          };
          xhr.send(null);
        }

        function dropAudio(texture) {    // called when a window with audio is closed
          if (texture.song) texture.song.stop();
          if (texture.microphone) { texture.microphone.disconnect(); texture.microphone = null; }
          let i = 0;
          while (i < activeAudio.length) {                  // Remove from list
            if (activeAudio[i] == texture) {
              activeAudio.splice(i,1);  // remove it
              console.log("activeAudio "+i+" removed");
              break;
            } else i++;
          }
        }

        function getAudioData(texture) {
          console.log("getting "+texture.url);
          if (texture.url === "microphone") {  // microphone needs permission
              navigator.mediaDevices.getUserMedia({audio: true}).then( function(stream) {
                texture.microphone = audioCtx.createMediaStreamSource(stream);
                texture.microphone.connect(texture.analyser);
                texture.analyser.connect(audioCtx.destination);
                activeAudio.push(texture);                          // Add this audioTexture to active list
                console.log("microphone connected");
              }, function(e) { console.error(e)});
          } else {
              request = new XMLHttpRequest();   // use XHR to load an audio track, and decodeAudioData to decode it to a buffer. Then we put the buffer into the source
              request.open('GET', texture.url, true);
              request.responseType = 'arraybuffer';
              request.onload = function() {
                audioCtx.decodeAudioData(request.response, function(buffer) {
                    texture.song = audioCtx.createBufferSource();
                    texture.song.buffer = buffer;
                    texture.song.connect(texture.analyser);
                    texture.analyser.connect(audioCtx.destination);
                    activeAudio.push(texture);                          // Add this audioTexture to active list
                    texture.song.addEventListener("ended", function() {
                      dropAudio(texture);
                    });
                    texture.song.start();
                });
              }
              request.send();
          }
        }

				function createQuadShader(u, blocks, fragglsl, fragparams) {		// A vanilla quad shader that uses the viewports projection
		      return new GP.VertexComputer({
		          units: 6,
		          type: GP.gl.TRIANGLES,
		          struct: { position: "vec2" },
              uniforms: u,
		          uniformBlocks: blocks,
		          initializeBuffer: GP.Util.quadBuffer(),
		          renderStep: {  glsl: `void main() {  gl_Position = u_projection * vec4(i_position,0.0,1.0); 	}   `, fragment: fragglsl, fragmentParams: fragparams }
		      });
		    }
        // utility function to return computer that renders a texture out of a uniform
        function createTextureShader(u, blocks, texname) {
            return createQuadShader(u, blocks, `
                    void main() {
                        vec2 uv = ((inverse(u_projection) * vec4((gl_FragCoord.xy/u_resolution.xy * 2.0 - 1.0),0.0,1.0)).xy + 1.0) / 2.0;
                        fragColor = texture(u_`+texname+`, uv);
                        fragColor.a += 0.5; // Boost the alpha so we see something
                    }`, { [texname]: "sampler2D"} );
        }
    </script>
</body>
</html>
