<!DOCTYPE html>
<html>
<head><title>WebGP-vm  A lightweight window manager for GPU viewports</title><meta charset="utf-8"></head>
<body style="margin: 0; background: linear-gradient(to bottom right, black, #333333); ">
    <canvas style="display: block; cursor: pointer; user-select: none;"></canvas>
    <script src="../src/webgp2.js"></script>
    <script src="toys/ClockMin.js"></script>
    <script src="toys/MicAnalysis.js"></script>
		<script src="toys/Primitives.js"></script>
		<script src="toys/Prism.js"></script>
    <script src="toys/Galaxy.js"></script>
    <script src="toys/Tunnel.js"></script>
    <script src="toys/FirstAudio.js"></script>
    <script src="toys/Terrain.js"></script>
		<script src="toys/StarToy.js"></script>
    <script src="toys/PlasmaBall.js"></script>
    <script src="toys/ClockSpiral.js"></script>
    <script src="toys/ClockCircles.js"></script>
    <script src="toys/Cubescape.js"></script>
    <script src="toys/Cubes.js"></script>
<!--    <script src="toys/Cube.js"></script>
    <script src="toys/Simplest.js"></script>
    <script src="toys/HG-SDF.js"></script>
    <script src="toys/Water.js"></script>
		<script src="toys/SDFx1.js"></script> -->
    <script>
				const VIEWPORT_MAX = 1000;		// Max number of viewports
				const MULTICLICK_MS = 330;	// ms delay to count clicks
                      // "Simplest",,"Cube","HGSDF","ClockCircles","SDFx1"
        let itemlist = ["ClockMin","Primitives","PlasmaBall","MicAnalysis","Terrain","FirstAudio","ClockSpiral","ClockCircles","Tunnel","StarToy","Galaxy","Prism","Cubes","Cubescape"];  //

				const cornerVectors = `
// These are used to locate the control points
#define sizerVector vec2(1.0, 1.0)
#define moverTVector vec2(0.5, 1.0)
#define moverRVector vec2(1.0, 0.5)
#define sizeVVector vec2(0.0, 1.0)
#define sizeHVector vec2(1.0, 0.0)
				`;

				const matrixFunctions = `
mat4 frustum(float angle_of_view, float aspect_ratio, float z_near, float z_far) {
	 return mat4( vec4(1.0/tan(angle_of_view), 0.0, 0.0, 0.0),
								vec4(0.0, aspect_ratio/tan(angle_of_view),  0.0, 0.0),
								vec4(0.0, 0.0, (z_far+z_near)/(z_far-z_near), 1.0),
								vec4(0.0, 0.0, -2.0*z_far*z_near/(z_far-z_near), 0.0) ); }

mat4 scale(float x, float y, float z) {	return mat4(vec4(x,   0.0, 0.0, 0.0),
																										vec4(0.0, y,   0.0, 0.0),
																										vec4(0.0, 0.0, z,   0.0),
																										vec4(0.0, 0.0, 0.0, 1.0)); }

mat4 translate(float x, float y, float z) { return mat4(vec4(1.0, 0.0, 0.0, 0.0),
																												vec4(0.0, 1.0, 0.0, 0.0),
																												vec4(0.0, 0.0, 1.0, 0.0),
																												vec4(x,   y,   z,   1.0)); }

mat4 rotate_x(float theta) { return mat4(	vec4(1.0,         0.0,         0.0, 0.0),
																					vec4(0.0,  cos(theta),  sin(theta), 0.0),
																					vec4(0.0, -sin(theta),  cos(theta), 0.0),
																					vec4(0.0,         0.0,         0.0, 1.0)); }

mat4 rotate_y(float theta) { return mat4(	vec4(cos(theta), 0.0, sin(theta), 0.0),
																					vec4(0.0,  1.0,  0.0, 0.0),
																					vec4(-sin(theta), 0.0, cos(theta), 0.0),
																					vec4(0.0,         0.0,         0.0, 1.0)); }

mat4 rotate_z(float theta) {	return mat4( vec4(cos(theta), -sin(theta), 0.0, 0.0),
																						vec4(sin(theta), cos(theta), 0.0, 0.0),
																						vec4(0.0, 0.0, 1.0, 0.0),
																						vec4(0.0, 0.0, 0.0, 1.0)); }

mat4 projection(vec4 viewport) {
		return  	//frustum(radians(45.0), u_resolution.x/u_resolution.y, 0.5, 5.0) *  // no frustum needed (yet?)
							translate(viewport.x + viewport.z/2.0, viewport.y + viewport.w/2.0, 0.0) *
							scale(viewport.z/2.0, viewport.w/2.0, 1.0);   }
				`;

        const canvas = document.querySelector("canvas");
				canvas.width = window.innerWidth - 1;
        canvas.height = window.innerHeight - 1;
        const GP = WebGP(canvas);

        // Comment this block to hide the log and controls
        //let log = GP.Util.initializeHeadsUpLog();
				let addNewItem = false;
        GP.Util.createShaderControls("GP");
				GP.Util.butdiv.append("           ");
				GP.Util.createButton("+", "addSomething();");
				GP.Util.createButton("Dump", "console.log(viewporter.getResultUnits().slice(0,stack.length));");
        let stats = document.createElement("paragraph");
        stats.appendChild(document.createTextNode(""));
        GP.Util.butdiv.appendChild(stats);

        // set up an audio context
        const audioCtx = new (window.AudioContext || window.webkitAudioContext)();

				const inputBlock = new GP.UniformBlock({		// This block is sent to the viewporter to relay to all blocks
            struct: {
								mouse: "vec4"
                ,date: "vec4"
								,resolution: "vec2"
								,now: "float"
                ,clicks: "int"
                ,wheel: "vec3"
            },
            initialize: {
								 mouse: [0.0,0.0,0.0,0.0]
                ,date: [0.0,0.0,0.0,0.0]  // Date in days
                ,resolution: [canvas.clientWidth, canvas.clientHeight]
								,now: window.performance.now()
                ,clicks: 0
                ,wheel: [0.0,0.0,0.0]
            }
        });

        // Feed mouse events into the inputBlock data
				let clickTime = 0.0, clicks = 0, mouse = [0.0, 0.0, 0.0, 0.0], wheel = [0.0, 0.0, 0.0], drag=false; dragFrom=[0,0];
				window.addEventListener('mousemove', e => { mouse[0]=e.clientX; mouse[1]=canvas.clientHeight-e.clientY; });   // if(e.buttons===0) drag=false;
				window.addEventListener('mouseup', e => { drag=false; mouse[2]=0.0; mouse[3]=0.0; });
        window.addEventListener('mousedown', e => { clicks=(Date.now()-clickTime<=MULTICLICK_MS)?clicks+1:1; clickTime=Date.now(); drag=true; dragFrom=[e.clientX,canvas.clientHeight-e.clientY]});
        window.addEventListener('wheel', e => { wheel=[e.deltaX, e.deltaY, e.deltaZ]; });

        // Resize updates the GL viewport and the resolution in the uniform block
				window.addEventListener('resize', event => {
					canvas.width = window.innerWidth - 1;
					canvas.height = window.innerHeight - 1;
					GP.gl.viewport(0, 0, canvas.clientWidth, canvas.clientHeight);
					inputBlock.set({ resolution: [canvas.clientWidth, canvas.clientHeight]});
				});

        const keyboardBlock = new GP.UniformBlock({		// This block is sent to interested components (names must correspond to values returned from keyevent.code)
            struct: {
								ArrowDown: "int", ArrowUp: "int",	ArrowLeft: "int", ArrowRight: "int", Escape: "int", Enter: "int", Minus: "int", Equal: "int", Delete: "int",
                Backslash: "int", Insert: "int", Home: "int", End: "int",  PageUp: "int", PageDown: "int", Space: "int", Backspace: "int", Tab: "int",
                F1: "int", F2: "int", F3: "int", F4: "int", F5: "int", F6: "int", F7: "int", F8: "int", F9: "int", F10: "int", F11: "int", F12: "int",
                ShiftLeft: "int",  ShiftRight: "int", ControlLeft: "int", ControlRight: "int", AltLeft: "int", AltRight: "int",
                Digit1: "int",  Digit2: "int",  Digit3: "int", Digit4: "int", Digit5: "int", Digit6: "int", Digit7: "int", Digit8: "int", Digit9: "int", Digit0: "int",
                KeyA: "int", KeyB: "int", KeyC: "int", KeyD: "int", KeyE: "int", KeyF: "int", KeyG: "int", KeyH: "int", KeyI: "int", KeyJ: "int",
                KeyK: "int", KeyL: "int", KeyM: "int", KeyN: "int", KeyO: "int", KeyP: "int", KeyQ: "int", KeyR: "int", KeyS: "int", KeyT: "int",
                KeyU: "int", KeyV: "int", KeyW: "int", KeyX: "int", KeyY: "int", KeyZ: "int"
            }
        });

        // Feed keyboard events to the keyboard block
        function keyModifier(e) { return e.altKey && e.shiftKey ? 2048 : e.ctrlKey && e.shiftKey ? 4096 : e.ctrlKey && e.altKey ? 8192 :e.altKey ? 256 : e.shiftKey ? 512 : e.ctrlKey ? 1024 : 0; }
				window.addEventListener('keydown', e => keyboardBlock.setWrite( {[e.code]: 1+keyModifier(e)} ));
				window.addEventListener('keyup', e => keyboardBlock.setWrite( {[e.code]: -1-keyModifier(e)} ));
				window.addEventListener('keypress', e => keyboardBlock.setWrite( {[e.code]: 2+keyModifier(e)} ));
        //        function logKey(t,e) { console.log("key"+t+" "+(e.altKey?"~":"")+(e.ctrlKey?"^":"")+(e.shiftKey?"_":"")+e.key+"  "+e.keyCode+"  "+e.code); }

			// common structure used by each viewport  (the viewporter maintains them all as a set)
			const viewStructure = {
					 viewport: "vec4",
              mouse: "vec4",
               date: "vec4",
				 resolution: "vec2",
					 		 time: "float",
					    delta: "float",
					      now: "float",
         sampleRate: "float",
					   clicks: "int",
              frame: "int",
              wheel: "vec3",
              state: "int",
				 projection: "mat4"
			};

			const viewInitial = {
				 viewport: [-2.0, -2.0, 0.0, 0.0],
					  mouse: [0.0, 0.0, 0.0, 0.0],
            date: [0.0, 0.0, 0.0, 0.0],
			 resolution: [0.0, 0.0],
						 time: -1.0,            //  time < 0 means dead
					  delta: 0.0,
							now: 0.0,
       sampleRate: 0.0,
					 clicks: 0,
 				    frame: 0,
            wheel: [0.0, 0.0, 0.0],
            state: 0,
			 projection: [-2.0,-2.0,-2.0,-2.0]
		 };

		 function viewBlock() {							// Each viewbox array will share one of these
				return new GP.UniformBlock({ struct: viewStructure,  initialize: viewInitial });
		 }

     console.log(viewBlock());

     // Texture used by viewporter to share viewport locations and sizes
     const VIEWTEXTURE_SIZE = GP.Util.data2d(VIEWPORT_MAX);
     const viewportUniforms = {   // vm system textures, not passed to items
         viewports: GP.Util.buildDataTexture(VIEWTEXTURE_SIZE,VIEWTEXTURE_SIZE)
     };

		// Maintains viewBlock information, location and size for each component
		const viewporter = new GP.VertexComputer({
				units: 1000,
				struct: viewStructure,
				initializeObject: (i) => { return viewInitial;	},
				uniforms: viewportUniforms,
        uniformBlocks: [inputBlock,keyboardBlock],
        textureOut: true,
				updateStep: {
            params: { viewports: "sampler2D" },
						glsl: cornerVectors + matrixFunctions + GP.Util.dataTextureMacros + `
#define VIEWPORT_MIN 0.07
#define AUTOMOVE_INCREMENT 0.01

void main() {
		if (i_time < 0.0) {  // Inactive or closed - copy everything
      o_viewport = i_viewport;
      o_mouse = i_mouse;
      o_date = i_date;
      o_resolution = u_resolution;
			o_time = i_time;
      o_delta = 0.0;
			o_now = u_now;
      o_sampleRate = i_sampleRate;
      o_clicks = i_clicks;
      o_frame = i_frame;
      o_wheel = i_wheel;
      o_state = i_state;
      o_projection = i_projection;

		} else {
			o_now = u_now;
//      o_date = vec4(trunc(u_date/365.24),trunc(u_date/30.44),trunc(mod(u_date,30.44)*30.44),mod(u_date,1.0)*86400.0);
      o_date = u_date;
			o_delta = u_now - i_now;
			o_time = i_time + o_delta/1000.0;  // Increment time for this unit
			o_resolution = u_resolution;
      o_frame = i_frame + 1;
      o_mouse = i_mouse;
			o_clicks = i_clicks;

      int newstate = i_state > 0 ? i_state : 0;  // default state to zero if not captured
      vec4 nv = i_viewport;              // new viewport

      if (u_ShiftLeft > 0 || u_ShiftRight > 0) {
        if (u_ArrowUp > 0)  nv.y = nv.y + 0.01;
        if (u_ArrowDown > 0)  nv.y = nv.y - 0.01;
        if (u_ArrowLeft > 0)  nv.x = nv.x - 0.01;
        if (u_ArrowRight > 0)  nv.x = nv.x + 0.01;
        if (u_wheel.x != 0.0) nv.x += u_wheel.x/u_resolution.x;
        if (u_wheel.y != 0.0) nv.y += u_wheel.y/u_resolution.y;
      }

      vec2 drag = 2.0 * u_mouse.zw/u_resolution;  // calculate mouse movement
      vec2 vpmouse = (inverse(i_projection) * vec4(u_mouse.xy / u_resolution * 2.0 - 1.0,0.0,1.0)).xy;  // convert mouse to viewport coord

			if (newstate < 1 && u_clicks > 0) {  // If dragging something or click
        float CLICK_THRESHOLD = 0.1 * 2.0/(i_viewport.z + i_viewport.w)/5.0;
				float distToMover = min(distance(moverTVector, abs(vpmouse)), distance(moverRVector,abs(vpmouse)));
				float distToSizer = distance(sizerVector,abs(vpmouse));
				float distToSizeVH = min(distance(sizeVVector,abs(vpmouse)),distance(sizeHVector,abs(vpmouse)));

				if (distToMover < CLICK_THRESHOLD && u_clicks == 3) {  					// CLOSE viewport on mover TRIPLE click
						o_time = -1.0;
						o_delta = 0.0;
						nv = vec4(-2.0,-2.0,0.0,0.0);
						o_mouse = vec4(0.0,0.0,0.0,0.0);
            o_frame = 0;
            o_state = 0;

				} else if (i_state == -1 || (i_state == 0 && distToMover < CLICK_THRESHOLD)) {                // moving
            nv.xy += drag;
            newstate = -1;

				} else if (i_state == -2 || (i_state == 0 && distToSizer < CLICK_THRESHOLD)) {                // Sizing
						if (sign(vpmouse.x) > 0.0 && sign(vpmouse.y) > 0.0) {          // top right
              nv.zw += drag;  // size it
						} else if (sign(vpmouse.x) > 0.0 && sign(vpmouse.y) < 0.0) {   // bottom right
							nv.zw = i_viewport.zw + vec2(drag.x, -drag.y);
							nv.xy = vec2(i_viewport.x, i_viewport.y + drag.y);
						} else if (sign(vpmouse.x) < 0.0 && sign(vpmouse.y) < 0.0) {   // Bottom left
							nv.zw =  i_viewport.zw - drag;
							nv.xy = i_viewport.xy + drag;
						} else {                                                   // Top left
							nv.zw =  i_viewport.zw + vec2(-drag.x, drag.y);
							nv.xy = vec2(i_viewport.x + drag.x,i_viewport.y);
						}
            newstate = -2;

				} else if (i_state == -3 || (i_state == 0 && distToSizeVH < CLICK_THRESHOLD)) {                    // size a side
					if (vpmouse.x > 0.0 && abs(vpmouse.y) < 0.4) {  					// right - horizontal - width
						nv.zw = i_viewport.zw + vec2( drag.x, 0.0);
					} else if (vpmouse.y > 0.0 && abs(vpmouse.x) < 0.4) {  		// top - vertical - height
						nv.zw =  i_viewport.zw + vec2(0.0, drag.y);
					} else if (vpmouse.y < 0.0 && abs(vpmouse.x) < 0.4) {  		// bottom - vertical - height
							nv.zw =  i_viewport.zw + vec2(0.0,-drag.y);
							nv.xy = vec2(i_viewport.x,i_viewport.y + drag.y);
					} else if (vpmouse.x < 0.0 && abs(vpmouse.y) < 0.4) {  			// left - horizontal - width
							nv.zw = i_viewport.zw + vec2(-drag.x,0.0);
							nv.xy = vec2(i_viewport.x + drag.x, i_viewport.y);
					}
          newstate = -3;
				}

	  }  // ends if clicked

    if (newstate == 0 && i_clicks == 0 && u_clicks > 0
      &&  lessThan(vec2(-0.99,-0.99),vpmouse) == lessThan(vpmouse,vec2(0.99,0.99))) {     // just clicked inside viewport
        newstate = 1;                                                                   // set mouse capture state
    }
    if (u_clicks == 0 && i_clicks > 0) {                              // just unclicked, capture off
      newstate = 0;
    }

    if (newstate > 0) {                                             // viewport mouse capture
      o_mouse.xy = vpmouse;
      o_mouse.zw = i_mouse.zw + drag;  // drag accumulates
      o_clicks = u_clicks;
    } else {
      o_clicks = 0;
    }

    if (u_clicks > 0 && newstate == 0 && i_state == 0) {                   // if not clicked on me, watch for others moving
        for (int i=0; i < ${VIEWPORT_MAX}; i++) {
            if (i != gl_VertexID) { // don't look at me
              vec4 ovp = TEXTURE_FETCH(u_viewports,i,${VIEWTEXTURE_SIZE});
              if (ovp.x == -2.0) break;  // reached end
              if (ovp.y < nv.y + nv.w && ovp.y + ovp.w > nv.y) {  // if aligned vertically
                if (nv.x > ovp.x && ovp.x + ovp.z > nv.x) {
                  nv.x += AUTOMOVE_INCREMENT;  // I move right if other is overlap from left
                }
                if (nv.x < ovp.x && nv.x + nv.z > ovp.x) {
                  nv.x -= AUTOMOVE_INCREMENT;  // I move left if other is overlap from right
                }
              }
              if (ovp.x < nv.x + nv.z && ovp.x + ovp.z > nv.x) {  // if aligned horizontally
                if (nv.y > ovp.y && ovp.y + ovp.w > nv.y) {
                  nv.y += AUTOMOVE_INCREMENT;  // I move up
                }
                if (nv.y < ovp.y && nv.y + nv.w > ovp.y) {
                  nv.y -= AUTOMOVE_INCREMENT;  // I move down
                }
              }
            }
        }
    }

    // Clamp location and size to GL space - boxes can't leave or be partially off screen
    if (nv.z > 2.0) nv.z = 2.0;
    if (nv.w > 2.0) nv.w = 2.0;
    if (nv.z < VIEWPORT_MIN || nv.w < VIEWPORT_MIN) { nv.zw = vec2(VIEWPORT_MIN,VIEWPORT_MIN); newstate = 0; }
    if (nv.x < -1.0) nv.x += AUTOMOVE_INCREMENT;
    if (nv.x+nv.z > 1.0) nv.x -= AUTOMOVE_INCREMENT;
    if (nv.y < -1.0) nv.y += AUTOMOVE_INCREMENT;
    if (nv.y+nv.w > 1.0) nv.y -= AUTOMOVE_INCREMENT;

    o_state = newstate;
    o_wheel = lessThan(vec2(-0.99,-0.99),u_mouse.xy) == bvec2(true,true) && lessThan(u_mouse.xy,vec2(0.99,0.99)) == bvec2(true,true) ? u_wheel : vec3(0.0, 0.0, 0.0);   // send wheel data only if mouse inside viewport
    o_projection = projection(nv);
    o_viewport = nv;

	}  // ends if time > 0.0  (if active)

  textureColor = o_viewport;
  gl_Position = TEXTURE_POS(gl_VertexID, ${VIEWTEXTURE_SIZE});
}`    },
								renderStep: {			// Renders nearest appropriate control point for a viewport
										glsl: cornerVectors+`
#define POINTSIZE_MAX 10.0
#define CLICKED_COLOR vec4(1.0,1.0,1.0,0.6)
#define HOVER_COLOR vec4(0.0,1.0,0.0,0.6)
#define TIME_MULT 10.0    // Animation time in ms
#define PULSE_SIZE 3.0
#define MOVE_FACTOR 150.0
vec4 jitter() {	return vec4(cos(i_time*TIME_MULT)/MOVE_FACTOR,sin(i_time*TIME_MULT)/MOVE_FACTOR*(i_resolution.x/i_resolution.y),0.,0.);	}

void main() {
    float CLICK_THRESHOLD = 0.1 * 2.0/(i_viewport.z + i_viewport.w)/5.0;
    vec2 vpmouse = (inverse(i_projection) * vec4(u_mouse.xy / u_resolution * 2.0 - 1.0,0.0,1.0)).xy;  // convert mouse to viewport coord
		float distToSizer = distance(sizerVector,abs(vpmouse.xy));
		float distToMover = min(distance(moverTVector, abs(vpmouse.xy)), distance(moverRVector,abs(vpmouse.xy)));
		float distToSizeVH = min(distance(sizeVVector,abs(vpmouse.xy)),distance(sizeHVector,abs(vpmouse.xy)));
		float md = CLICK_THRESHOLD * 25.0;
		float pulse = 0.0;
		float dist;
		if (distToMover < md && distToMover < distToSizer && distToMover < distToSizeVH) {
				dist = distToMover;
        gl_Position =  i_projection * vec4((abs(vpmouse.x) > abs(vpmouse.y) ? moverRVector : moverTVector) * sign(vpmouse.xy),0.0,1.0)
        	+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : jitter());
		} else if (distToSizer < md && distToSizer < distToMover && distToSizer < distToSizeVH) {
					dist = distToSizer;
					gl_Position =  i_projection * vec4(sizerVector * sign(vpmouse.xy),0.0,1.0)
							+ (dist < CLICK_THRESHOLD ? vec4(0.,0.,0.,0.) : vec4(jitter().x * sign(vpmouse.x), jitter().x * sign(vpmouse.y), 0.,0.));
		} else if (distToSizeVH < md && distToSizeVH < distToSizer && distToSizeVH < distToMover) {
				dist = distToSizeVH;
				gl_Position =  i_projection * vec4( (abs(vpmouse.x) > abs(vpmouse.y) ? sizeHVector : sizeVVector) * sign(vpmouse.xy),0.0,1.0)
						+ (dist < CLICK_THRESHOLD	? vec4(0.,0.,0.,0.)	: abs(vpmouse.x) > abs(vpmouse.y) ? vec4(jitter().x,0.,0.,0.) : vec4(0.,jitter().y,0.,0.));
		}
		//pulse = (dist < CLICK_THRESHOLD ? sin(i_time*TIME_MULT*10.0) * PULSE_SIZE : 0.0 );
		gl_PointSize = dist < CLICK_THRESHOLD && u_clicks > 0 ? POINTSIZE_MAX * 1.5 :    // when clicked
										max(0.5, POINTSIZE_MAX - dist/md * POINTSIZE_MAX); // + pulse;
		vertexColor = dist < CLICK_THRESHOLD && u_clicks > 0 ? (u_clicks > 1 ? vec4(1.0,0.0,0.0,1.0) : CLICKED_COLOR) :    // when clicked, white
										 dist < CLICK_THRESHOLD ? HOVER_COLOR : vec4(1.0 - dist/md,0.0,0.0,0.6);
}`}
});

				let watch = GP.Util.stopWatch();
				const stack = [];   // Viewports to draw, each element is an array of GPU shaders that share a viewport uniformBlock
        let checkStack = false;
        const activeAudio = [];
        let date = new Date();

        function loop() {
            watch.mark();
						GP.Util.clear();

            date.setTime(Date.now());
						clicks = (Date.now()-clickTime <= MULTICLICK_MS) ? clicks : drag ? 1 : 0;   // clear clicks if time has passed
            if (drag) {  // send mouse difference each cycle when dragging
              mouse[2] = mouse[0] - dragFrom[0];  dragFrom[0] = mouse[0];
              mouse[3] = mouse[1] - dragFrom[1];  dragFrom[1] = mouse[1];  // console.log(mouse);  // can be handy
            }
						inputBlock.set({
								mouse: mouse,
                date: [date.getFullYear(),date.getMonth()+1,date.getDate(),date.getHours()*3600+date.getMinutes()*60+date.getSeconds()],
								now: window.performance.now(),     // time since start of browser, very accurate to micro seconds
                wheel: wheel,
								clicks: clicks
						}).write();  // Write all at once - other values may have changed via events
            wheel = [0.0,0.0,0.0];

            viewporter.step();  // Update the viewports
            viewportUniforms.viewports = viewporter.getResultTexture();

            activeAudio.map(audioTexture => audioTexture.update());  // update active audio textures
						stack.map((item,index) => {
							viewporter.copyUnitToBlock(index,item[0].uniformBlocks[0]);	// All shaders in item must share uniformBlocks, first in array is always the viewblock
							item.map(layer => { if (layer.ready) layer.step(); else layer.ready=checkUniforms(layer);  } );
						});

            if (clicks == 3 && checkStack == false) {
              checkStack = true;
            }
						if (watch.check() % 100 === 0) {
                stats.innerText = watch.stats();  watch.reset();
                if (checkStack) cleanStack();   // something may have been deleted
            }
            GP.Util.GPControls(loop);
        }

				let nextcomp = 0;
				addSomething();    // to start with something
        //addItem([createTextureShader(uniforms,[viewBlock()],"viewports")]);  // Uncomment to see the viewports texture
        loop();

				// Utility functions  ==================================
				function addSomething() {
					if (nextcomp > itemlist.length-1) nextcomp = 0;    // Update Max here
					addItem(itemlist[nextcomp++]);
				}

				function addItem(itemname) {
          item = loadKit(itemname);
          for (let layer of item) {
            layer.ready = !layer.uniforms || Object.keys(layer.uniforms).length == 0 ? true : checkUniforms(layer);  // Uniforms must be validated before step if there are textures to load
            if (layer.audio) {   // Load audio and start when opening item
              layer.audio.map(at => getAudioData(at));
            }
          }
					if (stack.length == VIEWPORT_MAX) { alert("out of viewport slots"); return; }
					viewporter.updateUnit(stack.length, {
						viewport: [Math.random()-0.5, Math.random()-0.5, 400/canvas.clientWidth, 300/canvas.clientHeight],  // random location and canvas size related size for now
						time: 0.0   // starts this item in the viewport engine
					});
					stack.push(item);
				}

				function loadKit(name) {
					let template = Kit[name];
					if (!template || !template.model || !template.renderStep.fragment) {
							console.log("trying to load "+name+" and could not even get a fragment in the renderStep, so sad, all I got was "+template);
					} else {
						if (template.model = "quad") {
								let blocks = [viewBlock()],  un = {}, params = {};
                if (template.resources) template.resources.map(i => blocks.push(getResource(i)));  // add resources to uniform block array
                if (template.textures) {
                  un = loadTextures(template.textures);  // load the image
                  for (i in un) params[i] = "sampler2D";  // add to frag params
                }
                if (template.audio) {
                  let aa = [];  // audio attachments
                  for (i in template.audio) {
                    let audioTexture = GP.Util.buildAudioTexture(audioCtx,template.audio[i]);
                    un[i] = audioTexture.texture;
                    params[i] = "sampler2D"; // add to frag params
                    aa.push(audioTexture);
                  }
                  let qs = createQuadShader(un, blocks, template.renderStep.fragment,params);
                  qs.audio = aa;  // attach the audio textures to be loaded when item is opened
                  return [qs];
                } else {
                    return [createQuadShader(un, blocks, template.renderStep.fragment,params)];  // ane item could have multiple layers sharing the viewport
                }
						} else {
							console.log("Don't yet know how to load a model type of "+template.model+" for item "+name+", you may have to teach me");
						}
					}
				}

        function checkUniforms(computer) {    // assumes all uniforms are textures
          let result = true;
          for (t in computer.uniforms) {
            if (!(computer.uniforms[t] instanceof WebGLTexture)) {
              console.log(t+" not ready");
              return false;                // returns false if any are not WebGL textures
            }
          }
          return result;
        }

        function cleanStack() {
            let i=0, dead=0, units = viewporter.getResultUnits();  // array of viewport objects
            while (i<stack.length) {
              if (dead > 0) {
                units[i] = units[i+dead];   // advance by the number of dead encountered
                viewporter.updateUnit(i,units[i]);
              }
              if (units[i].time == -1.0) {   // dead unit
                let deaditem = stack[i];
                for (let layer of deaditem) {
                  if (layer.audio) layer.audio.map(at => dropAudio(at));  // Stop audio playing and copying
                  layer.destroy();
                }
                stack.splice(i,1);  // remove from stack
                dead++;  // will have to copy up from now til end
              } else i++;   // only advance if alive
            }
            checkStack = false;  // job is done
        }

        function getResource(r) {  // add other resources
          switch(r) {
            case "keyboard": return keyboardBlock;
          }
        }

        function loadTextures(un) {  // load a set of textures defined in a uniform structure with urls
          for (i in un) if (!(un[i] instanceof WebGLTexture)) loadTexture(un[i],i,un);
          return un;
        }

        function loadTexture(src, name, u) {    // load an image texture
          let xhr = new XMLHttpRequest();
          xhr.open("GET", src, true);
          xhr.responseType = "blob";
          xhr.onload = function(e) {
              let image = new Image();
              image.onload = function() {
                  console.log(name+ " loaded from "+src);
                  u[name] = GP.Util.buildImageTexture(this);
                  window.URL.revokeObjectURL(image.src);  // clean up
              };
              image.src = window.URL.createObjectURL(this.response);
          };
          xhr.send(null);
        }

        function dropAudio(texture) {    // called with an audio texture when a window with audio is closed
          if (texture.song) texture.song.stop();
          if (texture.microphone) { texture.microphone.disconnect(); texture.microphone = null; }
          let i = 0;
          while (i < activeAudio.length) {                  // Remove from list
            if (activeAudio[i] == texture) {
              activeAudio.splice(i,1);  // remove it
              console.log("activeAudio "+i+" removed");
              break;
            } else i++;
          }
        }

        function getAudioData(texture) {
          console.log("getting "+texture.url);
          if (texture.url === "microphone") {  // microphone needs permission
              navigator.mediaDevices.getUserMedia({audio: true}).then( function(stream) {
                texture.microphone = audioCtx.createMediaStreamSource(stream);
                texture.microphone.connect(texture.analyser);
                texture.analyser.connect(audioCtx.destination);
                activeAudio.push(texture);                          // Add this audioTexture to active list
                console.log("microphone connected");
              }, function(e) { console.log("microphone permission denied: "+e)});
          } else {
              request = new XMLHttpRequest();   // use XHR to load an audio track, and decodeAudioData to decode it to a buffer. Then we put the buffer into the source
              request.open('GET', texture.url, true);
              request.responseType = 'arraybuffer';
              request.onload = function() {
                audioCtx.decodeAudioData(request.response, function(buffer) {
                    texture.song = audioCtx.createBufferSource();
                    texture.song.buffer = buffer;
                    texture.song.connect(texture.analyser);
                    texture.analyser.connect(audioCtx.destination);
                    activeAudio.push(texture);                          // Add this audioTexture to active list
                    texture.song.addEventListener("ended", function() {
                      dropAudio(texture);
                    });
                    texture.song.start();
                });
              }
              request.send();
          }
        }

				function createQuadShader(u, blocks, fragglsl, fragparams) {		// A vanilla quad shader that uses the viewports projection
		      return new GP.VertexComputer({
		          units: 6,
		          type: GP.gl.TRIANGLES,
		          struct: { position: "vec2" },
              uniforms: u,
		          uniformBlocks: blocks,
		          initializeBuffer: GP.Util.quadBuffer(),
		          renderStep: {  glsl: `void main() {  gl_Position = u_projection * vec4(i_position,0.0,1.0); 	}   `, fragment: fragglsl, fragmentParams: fragparams }
		      });
		    }
        // utility function to return computer that renders a texture out of a uniform
        function createTextureShader(u, blocks, texname) {
            return createQuadShader(u, blocks, `
                    void main() {
                        vec2 uv = ((inverse(u_projection) * vec4((gl_FragCoord.xy/u_resolution.xy * 2.0 - 1.0),0.0,1.0)).xy + 1.0) / 2.0;
                        fragColor = texture(u_`+texname+`, uv);
                        fragColor.a += 0.5; // Boost the alpha so we see something
                    }`, { [texname]: "sampler2D"} );
        }
    </script>
</body>
</html>
